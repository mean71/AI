{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rc(\"font\", family = \"gulim\")\n",
    "plt.rc(\"axes\", unicode_minus = False)\n",
    "\n",
    "fpath = \"./01_Data_handling/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = sns.load_dataset(\"iris\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier # K-최근접 이웃(KNN) 알고리즘을 사용하여 분류 문제를 해결하기 위한 클래스\n",
    "#KNN은 새로운 데이터를 예측할 때 가장 가까운 K개의 데이터를 참조하여 다수결로 결과를 결정하는 비모수적 분류 방법\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 배우려고 일일히 했지만 앞으로는 이렇게 라이브러리를 쓰면 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "X = iris_df.iloc[:, :-1]\n",
    "y = iris_df.iloc[:, -1]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y, = train_test_split(\n",
    "    X, y, test_size = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler(with_mean=True, with_std=True) # 정규화한다면 sklearn에서는 다 이걸쓴다.\n",
    "ss.fit(train_X)\n",
    "\n",
    "train_scaled = ss.transform(train_X)\n",
    "test_scaled = ss.transform(test_X)\n",
    "print(ss.mean_)\n",
    "print(ss.scale_)\n",
    "print(ss.n_features_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_scaled = ss.fit_transform(train_X) # 위처럼 안하고 이렇게 변환 하면 변환하고 나서 파라미터를 쓸수가 없다\n",
    "# fit 트랜스폼은 어떤 때 쓰는가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타입 넘파이어레이\n",
    "print(type(train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_scaled, train_y)\n",
    "print(\"Train acc = {:.4f}\".format(knn.score(train_scaled, train_y)))\n",
    "print(\"Test acc = {:.4f}\".format(knn.score(test_scaled, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attribute\n",
    "print(\"classes = \", knn.classes_)\n",
    "# print(\"feature = \", knn.feature_names_in_)\n",
    "print(\"metric = \", knn.effective_metric_) # : 평가지표\n",
    "print(\"sample = \", knn.n_samples_fit_)\n",
    "print(\"n neighbors = \", knn.n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "wine = pd.read_csv(\"https://bit.ly/wine-date\")\n",
    "print(wine.head())\n",
    "print(wine.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine[\"class\"] = wine[\"class\"].astype(\"int32\").astype(\"category\")\n",
    "wine.info()\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(wine, x = \"class\", y = \"sugar\")\n",
    "plt.ylim(0, 35)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(wine, x = \"class\", y = \"alcohol\")\n",
    "plt.ylim(5, 20)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(wine, x = \"class\", y = \"pH\")\n",
    "plt.ylim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine.head()\n",
    "X = wine.iloc[:, :-1]\n",
    "y = wine.iloc[:, -1]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X, y, test_size=0.2\n",
    ")\n",
    "\n",
    "print(\"train shape = \", train_X.shape)\n",
    "print(\"test shape = \", test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling\n",
    "standScaler = StandardScaler()\n",
    "standScaler.fit(train_X)\n",
    "\n",
    "print(standScaler.mean_)\n",
    "print(standScaler.scale_)\n",
    "\n",
    "train_scaled = standScaler.transform(train_X)\n",
    "test_scaled = standScaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, max_leaf_nodes=10) # 오버피팅?\n",
    "# max_depth=5 더했더니 트레인이 떨어지고 테스트랑 비슷해짐 # max_leaf_nodes 마지막 leaf노드를 제어해서 오버피팅을 방지\n",
    "dt.fit(train_scaled, train_y)\n",
    "# 맞출때까지 끝까지 노드타고 비교해서 내려가니 트레인을 거의 다 맞춘다\n",
    "print(\"Train acc = \", dt.score(train_scaled, train_y))\n",
    "print(\"Test acc = \", dt.score(test_scaled, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plot_tree(dt, max_depth=3, filled=True) # filled\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt.feature_importances_)\n",
    "\n",
    "pd.DataFrame(dt.feature_importances_, index = train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 교차검증 (Cross validation, cv)\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_X_scaled = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedKFold(n_splits=5, shuffle=True) # stratigied가 비율을 반영해서 뽑는다\n",
    "cv_result = cross_validate(dt, cv_X_scaled, y, cv = 5) # train_scaled, train_y, cv = 5\n",
    "# 데이터 전체를 나누지않고 갖다 쓸 수 있...나..?\n",
    "# cv는 사실상 학습에 모든데이터를 학습하고 test는 학습에 참여하지 않지만 \n",
    "# cv한다고 할땐 굳이 train 과 test를 나눌필요가 없다?\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_result[\"test_score\"].mean()) # 데이터를 나누지 않더라도 그에 준하는 결과값을 cross_validation 하면 된다?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GridSearch\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "params = {\n",
    "    \"min_impurity_decrease\": np.arange(0.001, 0.01, 0.0001),\n",
    "    \"max_depth\": [5, 30, 1],\n",
    "    \"min_samples_split\": np.arange(2, 100, 10)\n",
    "}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "# cv_result = cross_validate(dt, cv_X_scaled, y, cv = splitter)\n",
    "\n",
    "grid_cv = GridSearchCV(dt,\n",
    "                       param_grid= params,\n",
    "                       cv = splitter)\n",
    "\n",
    "grid_cv.fit(cv_X_scaled, y)\n",
    "print(grid_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_cv.best_params_)\n",
    "print(np.mean(grid_cv.cv_results_[\"mean_test_score\"]))\n",
    "# 트리가 가장 설명하기 쉬워서 예를 들지만 모든 알고리즘이 gridsearch가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest # 스케일링 할 필요 없음음\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "print(y)\n",
    "print(cv_X_scaled.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": [50, 80, 100, 120],\n",
    "    \"max_depth\": [3, 5, 7, 9, 12, 15]\n",
    "}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid_rf = GridSearchCV(rf, param_grid=params, cv = splitter)\n",
    "grid_rf.fit(cv_X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_rf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_rf.best_params_)\n",
    "print(grid_rf.cv_results_[\"mean_test_score\"])\n",
    "print(grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(n_estimators=120,\n",
    "                                 max_depth=15)\n",
    "rf_best.fit(cv_X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_best.feature_importances_)\n",
    "print(rf_best.score(cv_X_scaled, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": [50, 80, 100, 120],\n",
    "    \"max_depth\": [3, 5, 7, 9, 12, 15]\n",
    "}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_score = cross_validate(gb, cv_X_scaled, y, cv = splitter)\n",
    "\n",
    "grid_gb = GridSearchCV(gb, param_grid=params, cv = splitter)\n",
    "\n",
    "grid_gb.fit(cv_X_scaled, y)\n",
    "# print(np.mean(cv_score[\"train_score\"]))\n",
    "# print(np.mean(cv_score[\"test_score\"]))\n",
    "\n",
    "# 랜텀포레스트는 뭘 찾으려하고 gb는 에러를 찾으려한다 보통 gb가 잘맞는다\n",
    "# 부스팅계열은 안맞는 샘플을 맞추려고 더 노력해서 일반적으로 gb알고리즘이 더 잘맞을 수 밖에 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_gb.best_params_)\n",
    "print(grid_gb.cv_results_[\"mean_test_score\"])\n",
    "print(grid_gb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DT, rf ,gb survived == 1 alive titanic 문제\n",
    "# 트리는 스케일링? 안해도 된다.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "print(titanic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.loc[:, :'fare']\n",
    "titanic.dropna(subset=[\"age\"], axis = 0, inplace=True)\n",
    "titanic.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature과 타겟변수 설정\n",
    "X = titanic.loc[:, 'pclass':'fare']\n",
    "y = titanic[\"survived\"]\n",
    "\n",
    "print(\"X shape = \",X.shape)\n",
    "print(\"y shape = \",y.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(titanic, columns = [\"sex\"], drop_first=True)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dt \n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": range(3, 20, 1),\n",
    "    \"max_leaf_nodes\": range(3, 20, 1)\n",
    "}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "\n",
    "gs_dt = GridSearchCV(dt, param_grid=params, cv = splitter)\n",
    "gs_dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters = \", gs_dt.best_estimator_)\n",
    "print(\"cv score = {:4f}\".format(gs_dt.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rf\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": range(90, 120, 1),\n",
    "    \"max_depth\": range(3, 15, 1)\n",
    "}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid_rf = GridSearchCV(rf, param_grid=params, cv = splitter)\n",
    "grid_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters = \", grid_rf.best_estimator_)\n",
    "print(\"cv score = {:4f}\".format(grid_rf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##gb # gb에 설명은 안했는데 꼭 해야하는 걸 하나 설명하고 끝낸다\n",
    "b = GradientBoostingClassifier()\n",
    "\n",
    "params = {\n",
    "    \"learning_rate\": np.arange(0.1, 1), # 요건 반드시 해야한다. gb에만 있는 파라미터이다\n",
    "    \"max_depth\": range(3, 5) # 트리계열에서 나오는 값이라 대충 비슷한 파라미터\n",
    "} # 리그래션은 이런 파라미터가 없고 뭐가 그룹이 없어서 크로스 어쩌고를 해야한다. 트레이닝과 테스트도 나눠야하고 등?\n",
    "# 값이 무지하게 많은게 아니라면 이값이 실제값과 거의 같다다\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "grid_gb = GridSearchCV(gb, param_grid=params, cv = splitter)\n",
    "grid_gb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters = \", grid_gb.best_estimator_)\n",
    "print(\"cv score = {:4f}\".format(grid_gb.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "wine = pd.read_csv(\"https://bit.ly/wine-date\")\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine[\"class\"] = wine[\"class\"].astype(\"int32\").astype(\"category\")\n",
    "wine.head()\n",
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.iloc[:, :-1]\n",
    "y = wine[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 반드시 스케일링을 하는게 좋다\n",
    "standScaler = StandardScaler()\n",
    "X_scaled = standScaler.fit_transform(X)\n",
    "X_scaled[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터가 gridshearch할게 없다\n",
    "lr = LogisticRegression(max_iter=100) # max_iter만 손댈게 있지마 이건 하이퍼 파라미터가 아니다\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "scores = cross_validate(lr, X_scaled, y, cv = splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores[\"test_score\"]) #아까 것? ? 이 더 좋지만 원리적으로 로지스틱도 되게 많이 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"probability = \\n\", lr.predict_proba(X_scaled[:10]))\n",
    "print(\"coefficient = \\n\", lr.coef_, lr.intercept_)\n",
    "print(\"classes = \\n\", lr.classes_)\n",
    "# 첫번째 P(x1)= 1/ 1+ e**-(1.79+0.53x1+1.65*x2 + -0.79*x3 #) 로오지스틱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DT, rf ,gb survived == 1 alive titanic 문제\n",
    "'''\n",
    "# train/test Split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)  # test_size 20%\n",
    "print(\"train shape = \", train_X.shape)\n",
    "print(\"test shape = \", test_X.shape)\n",
    "# scaling\n",
    "standScaler = StandardScaler() # 스케일링 클래스 객체 생성\n",
    "standScaler.fit(train_X) # 훈련 데이터로 스케일링 객체 학습\n",
    "# 스케일러의 평균과 스케일링 파라미터 확인\n",
    "print(standScaler.mean_)\n",
    "print(standScaler.scale_)'''\n",
    "\n",
    "## dt\n",
    "# 결정트리 모델 생성  (gini 기준, max_depth 5, max_leaf_nodes 10)\n",
    "dt = DecisionTreeClassifier(criterion=\"gini\", max_depth=5, max_leaf_nodes=10) # 오버피팅?\n",
    "# max_depth=5 더했더니 트레인이 떨어지고 테스트랑 비슷해짐 # max_leaf_nodes 마지막 leaf노드를 제어해서 오버피팅을 방지\n",
    "dt.fit(train_scaled, train_y) # 훈련 데이터로 모델 학습\n",
    "# 훈련 데이터와 테스트 데이터에서의 정확도 확인 # 맞출때까지 끝까지 노드타고 비교해서 내려가니 트레인을 거의 다 맞춘다\n",
    "print(\"Train acc = \", dt.score(train_scaled, train_y))\n",
    "print(\"Test acc = \", dt.score(test_scaled, test_y))\n",
    "# 의사결정 트리 시각화\n",
    "plot_tree(dt, max_depth=3, filled=True) # filled\n",
    "plt.show()\n",
    "\n",
    "# print(dt.feature_importances_)\n",
    "# pd.DataFrame(dt.feature_importances_, index = train_X.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
