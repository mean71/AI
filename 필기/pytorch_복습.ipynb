{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "torch.Size([4])\n",
      "<built-in method type of Tensor object at 0x00000283443019D0>\n",
      "tensor([1.0000, 2.0000, 3.1000, 4.0000])\n"
     ]
    }
   ],
   "source": [
    "# numpy와 닯은 파이토치(pytorch)\n",
    "import torch\n",
    "a = torch.tensor([1,2,3,4]) # list가 입력으로 들어가는 함수\n",
    "print(a)\n",
    "print(type(a))\n",
    "print(a.dtype) # data type\n",
    "print(a.shape)\n",
    "b = torch.tensor([1,2,3.1,4])\n",
    "print(b.type) # 하나라도 실수면 자동으로 실수 타입으로\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n",
      "torch.Size([2, 3])\n",
      "2\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1,2,3],[3,4,5]]) # 이 셀부터는 import torch 는 실행했따 치고 작성\n",
    "# A = torch.tensor([ [1,2], [3,4,5] ]) # 리스트와는 달리 이제는 행렬이라서 각 행에 해당하는 숫자의 개수가 같아야 한다.\n",
    "print(A)\n",
    "print(A.shape)\n",
    "print(A.ndim) # 차원의 수\n",
    "print(A.numel()) # 전체 성분의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([3, 5, 7, 9])\n",
      "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "        0.9000])\n",
      "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.zeros(5))\n",
    "print(torch.zeros_like(A)) # A와 같은 크기의 0으로 이루어진 텐서\n",
    "print(torch.ones(5))\n",
    "print(torch.zeros(3,3))\n",
    "print(torch.arange(3, 10, 2)) # range와 같은데 tensor로 반환\n",
    "print(torch.arange(0, 1, 0.1)) # 실수값도 가능\n",
    "print(torch.linspace(0, 1, 10)) # 0에서 부터 1 포함 10개로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "c = a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 9],\n",
      "        [2, 3, 4]])\n",
      "tensor([[-3, -3, -3],\n",
      "        [ 0,  1,  2]])\n",
      "\n",
      "tensor([[ 4, 10, 18],\n",
      "        [ 1,  2,  3]])\n",
      "tensor([[0.2500, 0.4000, 0.5000],\n",
      "        [1.0000, 2.0000, 3.0000]])\n",
      "tensor([[  1,  32, 729],\n",
      "        [  1,   2,   3]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1,2,3], [1,2,3]])\n",
    "B = torch.tensor([[4,5,6], [1,1,1]])\n",
    "C = A+B\n",
    "D = A-B\n",
    "print(C)\n",
    "print(D)\n",
    "print()\n",
    "print(A*B) # 곱하기는 element-wise 성분끼리의 곱 (Hadamard product)\n",
    "print(A/B) # 나누기도\n",
    "print(A**B) # 제곱도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([1,2], [3,4])\n",
    "B = torch.tensor([1,2], [3,4])\n",
    "print(A*B)\n",
    "print(A@B) # 행렬 곱 # torch.matmul(A, B)와 같다. 하지만 @가 더 간단하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch의 인덱싱과 슬라이싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(9)\n",
      "tensor([2, 3, 4])\n",
      "tensor([8, 9])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4,5,6,7,8,9])\n",
    "# 인덱싱과 슬라이싱, list할 때와 동일!\n",
    "print(a[0])\n",
    "print(a[1])\n",
    "print(a[-1])\n",
    "print(a[1:4])\n",
    "print(a[7:])\n",
    "print(a[:7])\n",
    "print(a[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([7, 8, 9])\n",
      "tensor([[4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "[[1, 2, 3, 4], [5, 6, 7, 8]]\n",
      "3\n",
      "tensor([4, 5, 6])\n",
      "tensor([4, 6])\n",
      "tensor([3, 6, 9])\n",
      "tensor([7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# 행렬 인덱싱과 슬라이싱\n",
    "A = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(A[0]) # 하나만 쓰면 행에 대한 인덱싱 (리스트 속 리스트 생각)\n",
    "print(A[-1])\n",
    "print(A[1:])\n",
    "print(A[:])\n",
    "print(A[0][2])\n",
    "print(A[0,2]) # 2차원 행렬도 동일한데, 리스트와 달리 이런 것도 됨\n",
    "B = [[1,2,3,4], [5,6,7,8]]\n",
    "print(B)\n",
    "print(B[0][2])\n",
    "# print(B[0,2]) # error!\n",
    "print(A[1,:]) # 1행 전체\n",
    "print(A[1,0:3:2]) # 1행의 0열부터 3열까지 2칸씩\n",
    "print(A[:,2]) # 전부, 2열만\n",
    "print(A[:][2]) # 2행만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "torch.Size([2, 3, 4])\n",
      "tensor(6)\n",
      "torch.Size([1, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# 3차원 행렬 인덱싱\n",
    "A = torch.tensor([ [[0,1,2,3], [4,5,6,7], [8,9,10,11]], \n",
    "                   [[12,13,14,15], [16,17,18,19], [20,21,22,23]] ])\n",
    "print(A)\n",
    "print(A.shape)\n",
    "print(A[0,1,2])\n",
    "\n",
    "a = torch.tensor([[[1,2,3,4]]]) # 대괄호가 하나 늘어나면 왼쪽에 shape값이 추가된다.\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 3, 19, 22,  5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리스트로 인덱싱\n",
    "print(A)\n",
    "A[[0,1,1,0], [0,1,2,1], [3,3,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([[False, False, False,  True],\n",
      "        [ True, False,  True, False]])\n",
      "tensor([4, 5, 7])\n",
      "tensor([[  1,   2,   3, 100],\n",
      "        [100,   3, 100,   3]])\n",
      "tensor([[1, 2],\n",
      "        [7, 8]])\n",
      "tensor([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# boolean 인덱싱\n",
    "a = [1,2,3,4,5,3,3]\n",
    "print(a==3) # 여러개 값 들어있는 리스트랑 3 달랑 하나만 같나? 다르다!\n",
    "A = torch.tensor([[1,2,3,4], [5,3,7,3]])\n",
    "print(A>3) # 리스트와 달리 각 성분에 대해 비교해 줌\n",
    "print(A[A>3]) # True, False가 담긴 행렬로 인덱싱 가능!!\n",
    "\n",
    "A[A>3] = 100\n",
    "print(A) # 그러면 이런 것도 가능하다! (3보다 큰 값들을 100으로 바꿔라)\n",
    "# boolean 인덱싱은 numpy에서도 가능했음 안된다면 아래처럼 해야한다\n",
    "# for i in range(A.shape[0]):\n",
    "#     for j in range(A.shape[1]):\n",
    "#         if A[i,j]>3:\n",
    "#             A[i,j] = 100\n",
    "\n",
    "A = torch.tensor([[1,2], [3,4], [5,6], [7,8]])\n",
    "B = torch.tensor([True, False, False, True]) # 행만 bool로 인덱싱 하는 것도 가능 \n",
    "print(A[B,:]) # 0행, 3행 슬라이싱\n",
    "\n",
    "b = torch.tensor([1,2,3,4])\n",
    "print(b[ [True, False, True, False] ]) # 그냥 리스트여도 됨\n",
    "c = [1,2,3,4]\n",
    "# c[[True, True, False, False]] # error! 리스트는 안됨 # pytorch numpy 이런 데서만 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(3)\n",
      "tensor([3, 4, 5])\n",
      "tensor([[3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "tensor([[2, 2, 2],\n",
      "        [3, 3, 3]])\n",
      "tensor([1, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[4, 5, 6],\n",
      "         [4, 5, 6]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x283490f9cd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcgAAAGiCAYAAABjzlbWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuHUlEQVR4nO3dfVhVdb7//xegbLTcoKFsKMXbNBXFNImm0kYSzOPRM52TmqVymZ6c7jFT5pv3c0LNY04Tk5N5eyo15/KmJoc0iulUpIU6aZlHHfJ+412wBQsVPr8/+rmnPXxAQTagPB/Xta7Yn/1en/Ve60Je7b3X2ivAGGMEAAB8BNZ2AwAA1EUEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABZ+C8jTp09rxIgRcjqdCgsL05gxY1RYWFjhOn379lVAQIDP8uijj/rUHDx4UAMHDlTjxo3VokULTZw4URcuXPDXbgAA6qkG/pp4xIgROnbsmDZv3qzz588rOTlZ48aN01tvvVXhemPHjtXMmTO9jxs3buz9uaSkRAMHDpTL5dJnn32mY8eOaeTIkWrYsKFeeOEFf+0KAKAeCvDHl5Xv3r1bnTt31hdffKFevXpJkjIyMnTffffp8OHDioqKsq7Xt29fxcbGasGCBdbn//KXv+hf/uVfdPToUUVEREiSFi5cqEmTJunEiRMKDg6u7l0BANRTfnkFmZ2drbCwMG84SlJCQoICAwO1ZcsW/du//Vu567755pt644035HK5NGjQIE2ZMsX7KjI7O1sxMTHecJSkxMREjR8/Xl9//bV69OhhnbO4uFjFxcXex6WlpTp9+rRuuOEGBQQEXOnuAgBqmDFGZ86cUVRUlAID/fNpoV8C0u12q0WLFr4batBAzZo1k9vtLne9Bx98UNHR0YqKitJXX32lSZMmac+ePVq7dq133p+HoyTv44rmTUtL04wZM6q6OwCAOurQoUO66aab/DJ3pQJy8uTJmjNnToU1u3fvrnIz48aN8/4cExOjyMhI9evXT/v371e7du2qPG9qaqpSUlK8jwsKCtSqVSt9/rl0/fVVnhao07p23VXbLQB+VCjpdjVp0sRvW6hUQE6YMEGjR4+usKZt27ZyuVw6fvy4z/iFCxd0+vRpuVyuy95eXFycJGnfvn1q166dXC6Xtm7d6lOTl5cnSRXO63A45HA4yoxff73kx2ML1DJ+uXHt8+fHZJUKyObNm6t58+aXrIuPj1d+fr5ycnLUs2dPSdKHH36o0tJSb+hdjh07dkiSIiMjvfP+13/9l44fP+59C3fz5s1yOp3q3LlzZXYFAIAK+eWTzVtuuUVJSUkaO3astm7dqk8//VSPP/64hg0b5j2D9ciRI+rUqZP3FeH+/fs1a9Ys5eTk6LvvvtM777yjkSNH6u6771a3bt0kSf3791fnzp318MMP629/+5vef/99Pf/883rsscesrxABAKgqv31RwJtvvqlOnTqpX79+uu+++3TnnXfqtdde8z5//vx57dmzR2fPnpUkBQcH64MPPlD//v3VqVMnTZgwQffff7/effdd7zpBQUH685//rKCgIMXHx+uhhx7SyJEjfa6bBACgOvjlOsi6zuPxKDQ0VLt28Rkkrl3R0QdquwXAj85I6qqCggI5nU6/bIHvYgUAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAwm8Befr0aY0YMUJOp1NhYWEaM2aMCgsLK6x/4okn1LFjRzVq1EitWrXSk08+qYKCAp+6gICAMsuqVav8tRsAgHqqgb8mHjFihI4dO6bNmzfr/PnzSk5O1rhx4/TWW29Z648ePaqjR49q3rx56ty5sw4cOKBHH31UR48e1Z/+9Cef2qVLlyopKcn7OCwszF+7AQCopwKMMaa6J929e7c6d+6sL774Qr169ZIkZWRk6L777tPhw4cVFRV1WfOsWbNGDz30kIqKitSgwU9ZHhAQoHXr1mnIkCFV7s/j8Sg0NFS7dklNmlR5GqBOi44+UNstAH50RlJXFRQUyOl0+mULfnmLNTs7W2FhYd5wlKSEhAQFBgZqy5Ytlz3PxR2/GI4XPfbYYwoPD1fv3r21ZMkSXSrji4uL5fF4fBYAACril7dY3W63WrRo4buhBg3UrFkzud3uy5rj5MmTmjVrlsaNG+czPnPmTP3yl79U48aNtWnTJv36179WYWGhnnzyyXLnSktL04wZMyq/IwCAeqtSryAnT55sPUnm58u33357xU15PB4NHDhQnTt31vTp032emzJlin7xi1+oR48emjRpkp577jm9+OKLFc6XmpqqgoIC73Lo0KEr7hEAcG2r1CvICRMmaPTo0RXWtG3bVi6XS8ePH/cZv3Dhgk6fPi2Xy1Xh+mfOnFFSUpKaNGmidevWqWHDhhXWx8XFadasWSouLpbD4bDWOByOcp8DAMCmUgHZvHlzNW/e/JJ18fHxys/PV05Ojnr27ClJ+vDDD1VaWqq4uLhy1/N4PEpMTJTD4dA777yjkJCQS25rx44datq0KQEIAKhWfvkM8pZbblFSUpLGjh2rhQsX6vz583r88cc1bNgw7xmsR44cUb9+/bRixQr17t1bHo9H/fv319mzZ/XGG2/4nEzTvHlzBQUF6d1331VeXp5uv/12hYSEaPPmzXrhhRf07LPP+mM3AAD1mN+ug3zzzTf1+OOPq1+/fgoMDNT999+vl19+2fv8+fPntWfPHp09e1aStG3bNu8Zru3bt/eZKzc3V61bt1bDhg2Vnp6uZ555RsYYtW/fXvPnz9fYsWP9tRsAgHrKL9dB1nVcB4n6gOsgcW27Sq+DBADgakdAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgUSMBmZ6ertatWyskJERxcXHaunVrhfVr1qxRp06dFBISopiYGG3cuNHneWOMpk6dqsjISDVq1EgJCQnau3evP3cBAFDP+D0gV69erZSUFE2bNk3btm1T9+7dlZiYqOPHj1vrP/vsMw0fPlxjxozR9u3bNWTIEA0ZMkS7du3y1sydO1cvv/yyFi5cqC1btui6665TYmKifvzxR3/vDgCgnggwxhh/biAuLk633XabXnnlFUlSaWmpWrZsqSeeeEKTJ08uUz906FAVFRXpz3/+s3fs9ttvV2xsrBYuXChjjKKiojRhwgQ9++yzkqSCggJFRERo2bJlGjZs2CV78ng8Cg0N1a5dUpMm1bSjQB0THX2gtlsA/OiMpK4qKCiQ0+n0yxb8+gry3LlzysnJUUJCwj82GBiohIQEZWdnW9fJzs72qZekxMREb31ubq7cbrdPTWhoqOLi4sqds7i4WB6Px2cBAKAifg3IkydPqqSkRBERET7jERERcrvd1nXcbneF9Rf/W5k509LSFBoa6l1atmxZpf0BANQf9eIs1tTUVBUUFHiXQ4cO1XZLAIA6zq8BGR4erqCgIOXl5fmM5+XlyeVyWddxuVwV1l/8b2XmdDgccjqdPgsAABXxa0AGBwerZ8+eyszM9I6VlpYqMzNT8fHx1nXi4+N96iVp8+bN3vo2bdrI5XL51Hg8Hm3ZsqXcOQEAqKwG/t5ASkqKRo0apV69eql3795asGCBioqKlJycLEkaOXKkbrzxRqWlpUmSnnrqKfXp00f//d//rYEDB2rVqlX68ssv9dprr0mSAgIC9PTTT+u3v/2tOnTooDZt2mjKlCmKiorSkCFD/L07AIB6wu8BOXToUJ04cUJTp06V2+1WbGysMjIyvCfZHDx4UIGB/3ghe8cdd+itt97S888/r9/85jfq0KGD1q9fr65du3prnnvuORUVFWncuHHKz8/XnXfeqYyMDIWEhPh7dwAA9YTfr4Osi7gOEvUB10Hi2naVXwcJAMDVioAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwIKABADAgoAEAMCCgAQAwKJGAjI9PV2tW7dWSEiI4uLitHXr1nJrFy1apLvuuktNmzZV06ZNlZCQUKZ+9OjRCggI8FmSkpL8vRsAgHrE7wG5evVqpaSkaNq0adq2bZu6d++uxMREHT9+3FqflZWl4cOH66OPPlJ2drZatmyp/v3768iRIz51SUlJOnbsmHdZuXKlv3cFAFCPBBhjjD83EBcXp9tuu02vvPKKJKm0tFQtW7bUE088ocmTJ19y/ZKSEjVt2lSvvPKKRo4cKemnV5D5+flav379ZfVQXFys4uJi72OPx6OWLVtq1y6pSZPK7xNwNYiOPlDbLQB+dEZSVxUUFMjpdPplC359BXnu3Dnl5OQoISHhHxsMDFRCQoKys7Mva46zZ8/q/Pnzatasmc94VlaWWrRooY4dO2r8+PE6depUuXOkpaUpNDTUu7Rs2bJqOwQAqDf8GpAnT55USUmJIiIifMYjIiLkdrsva45JkyYpKirKJ2STkpK0YsUKZWZmas6cOfrrX/+qAQMGqKSkxDpHamqqCgoKvMuhQ4eqvlMAgHqhQW03UJHZs2dr1apVysrKUkhIiHd82LBh3p9jYmLUrVs3tWvXTllZWerXr1+ZeRwOhxwOR430DAC4Nvj1FWR4eLiCgoKUl5fnM56XlyeXy1XhuvPmzdPs2bO1adMmdevWrcLatm3bKjw8XPv27bvingEAkPwckMHBwerZs6cyMzO9Y6WlpcrMzFR8fHy5682dO1ezZs1SRkaGevXqdcntHD58WKdOnVJkZGS19A0AgN8v80hJSdGiRYu0fPly7d69W+PHj1dRUZGSk5MlSSNHjlRqaqq3fs6cOZoyZYqWLFmi1q1by+12y+12q7CwUJJUWFioiRMn6vPPP9d3332nzMxMDR48WO3bt1diYqK/dwcAUE/4/TPIoUOH6sSJE5o6darcbrdiY2OVkZHhPXHn4MGDCgz8R06/+uqrOnfunP793//dZ55p06Zp+vTpCgoK0ldffaXly5crPz9fUVFR6t+/v2bNmsXnjACAauP36yDrIo/Ho9DQUK6DxDWN6yBxbbvKr4MEAOBqRUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBBQAIAYEFAAgBgQUACAGBRIwGZnp6u1q1bKyQkRHFxcdq6dWu5tcuWLVNAQIDPEhIS4lNjjNHUqVMVGRmpRo0aKSEhQXv37vX3bgAA6hG/B+Tq1auVkpKiadOmadu2berevbsSExN1/PjxctdxOp06duyYdzlw4IDP83PnztXLL7+shQsXasuWLbruuuuUmJioH3/80d+7AwCoJ/wekPPnz9fYsWOVnJyszp07a+HChWrcuLGWLFlS7joBAQFyuVzeJSIiwvucMUYLFizQ888/r8GDB6tbt25asWKFjh49qvXr11vnKy4ulsfj8VkAAKhIA39Ofu7cOeXk5Cg1NdU7FhgYqISEBGVnZ5e7XmFhoaKjo1VaWqpbb71VL7zwgrp06SJJys3NldvtVkJCgrc+NDRUcXFxys7O1rBhw8rMl5aWphkzZpQZ73olOwcAuKb59RXkyZMnVVJS4vMKUJIiIiLkdrut63Ts2FFLlizRhg0b9MYbb6i0tFR33HGHDh8+LEne9SozZ2pqqgoKCrzLoUOHrnTXAADXOL++gqyK+Ph4xcfHex/fcccduuWWW/THP/5Rs2bNqtKcDodDDoejuloEANQDfn0FGR4erqCgIOXl5fmM5+XlyeVyXdYcDRs2VI8ePbRv3z5J8q53JXMCAHApfg3I4OBg9ezZU5mZmd6x0tJSZWZm+rxKrEhJSYl27typyMhISVKbNm3kcrl85vR4PNqyZctlzwkAwKX4/S3WlJQUjRo1Sr169VLv3r21YMECFRUVKTk5WZI0cuRI3XjjjUpLS5MkzZw5U7fffrvat2+v/Px8vfjiizpw4IAeeeQRST+d4fr000/rt7/9rTp06KA2bdpoypQpioqK0pAhQ/y9OwCAesLvATl06FCdOHFCU6dOldvtVmxsrDIyMrwn2Rw8eFCBgf94Ifv9999r7Nixcrvdatq0qXr27KnPPvtMnTt39tY899xzKioq0rhx45Sfn68777xTGRkZZb5QAACAqgowxpjabqKmeTwehYaGSrskNantbgA/iT5w6RrgqnVGUlcVFBTI6XT6ZQt8FysAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFjUSkOnp6WrdurVCQkIUFxenrVu3llvbt29fBQQElFkGDhzorRk9enSZ55OSkmpiVwAA9UQDf29g9erVSklJ0cKFCxUXF6cFCxYoMTFRe/bsUYsWLcrUr127VufOnfM+PnXqlLp3767/+I//8KlLSkrS0qVLvY8dDof/dgIAUO/4/RXk/PnzNXbsWCUnJ6tz585auHChGjdurCVLlljrmzVrJpfL5V02b96sxo0blwlIh8PhU9e0aVN/7woAoB7xa0CeO3dOOTk5SkhI+McGAwOVkJCg7Ozsy5pj8eLFGjZsmK677jqf8aysLLVo0UIdO3bU+PHjderUqXLnKC4ulsfj8VkAAKiIXwPy5MmTKikpUUREhM94RESE3G73JdffunWrdu3apUceecRnPCkpSStWrFBmZqbmzJmjv/71rxowYIBKSkqs86SlpSk0NNS7tGzZsuo7BQCoF/z+GeSVWLx4sWJiYtS7d2+f8WHDhnl/jomJUbdu3dSuXTtlZWWpX79+ZeZJTU1VSkqK97HH4yEkAQAV8usryPDwcAUFBSkvL89nPC8vTy6Xq8J1i4qKtGrVKo0ZM+aS22nbtq3Cw8O1b98+6/MOh0NOp9NnAQCgIn4NyODgYPXs2VOZmZnesdLSUmVmZio+Pr7CddesWaPi4mI99NBDl9zO4cOHderUKUVGRl5xzwAASDVwFmtKSooWLVqk5cuXa/fu3Ro/fryKioqUnJwsSRo5cqRSU1PLrLd48WINGTJEN9xwg894YWGhJk6cqM8//1zfffedMjMzNXjwYLVv316JiYn+3h0AQD3h988ghw4dqhMnTmjq1Klyu92KjY1VRkaG98SdgwcPKjDQN6f37NmjTz75RJs2bSozX1BQkL766istX75c+fn5ioqKUv/+/TVr1iyuhQQAVJsAY4yp7SZqmsfjUWhoqLRLUpPa7gbwk+gDtd0B4EdnJHVVQUGB384r4btYAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALAgIAEAsCAgAQCwICABALDwa0B+/PHHGjRokKKiohQQEKD169dfcp2srCzdeuutcjgcat++vZYtW1amJj09Xa1bt1ZISIji4uK0devW6m8eAFCv+TUgi4qK1L17d6Wnp19WfW5urgYOHKh77rlHO3bs0NNPP61HHnlE77//vrdm9erVSklJ0bRp07Rt2zZ1795diYmJOn78uL92AwBQDwUYY0yNbCggQOvWrdOQIUPKrZk0aZLee+897dq1yzs2bNgw5efnKyMjQ5IUFxen2267Ta+88ookqbS0VC1bttQTTzyhyZMnX1YvHo9HoaGh0i5JTaq8S0DdFn2gtjsA/OiMpK4qKCiQ0+n0yxbq1GeQ2dnZSkhI8BlLTExUdna2JOncuXPKycnxqQkMDFRCQoK3xqa4uFgej8dnAQCgInUqIN1utyIiInzGIiIi5PF49MMPP+jkyZMqKSmx1rjd7nLnTUtLU2hoqHdp2bKlX/oHAFw76lRA+ktqaqoKCgq8y6FDh2q7JQBAHdegthv4OZfLpby8PJ+xvLw8OZ1ONWrUSEFBQQoKCrLWuFyucud1OBxyOBx+6RkAcG2qU68g4+PjlZmZ6TO2efNmxcfHS5KCg4PVs2dPn5rS0lJlZmZ6awAAqA5+DcjCwkLt2LFDO3bskPTTZRw7duzQwYMHJf301ufIkSO99Y8++qj+/ve/67nnntO3336rP/zhD3r77bf1zDPPeGtSUlK0aNEiLV++XLt379b48eNVVFSk5ORkf+4KAKCe8etbrF9++aXuuece7+OUlBRJ0qhRo7Rs2TIdO3bMG5aS1KZNG7333nt65pln9Lvf/U433XSTXn/9dSUmJnprhg4dqhMnTmjq1Klyu92KjY1VRkZGmRN3AAC4EjV2HWRdwnWQqBe4DhLXtHp2HSQAAHUFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgAUBCQCABQEJAIAFAQkAgIVfA/Ljjz/WoEGDFBUVpYCAAK1fv77C+rVr1+ree+9V8+bN5XQ6FR8fr/fff9+nZvr06QoICPBZOnXq5Me9AADUR34NyKKiInXv3l3p6emXVf/xxx/r3nvv1caNG5WTk6N77rlHgwYN0vbt233qunTpomPHjnmXTz75xB/tAwDqsQb+nHzAgAEaMGDAZdcvWLDA5/ELL7ygDRs26N1331WPHj284w0aNJDL5aquNgEAKKNOfwZZWlqqM2fOqFmzZj7je/fuVVRUlNq2basRI0bo4MGDFc5TXFwsj8fjswAAUJE6HZDz5s1TYWGhHnjgAe9YXFycli1bpoyMDL366qvKzc3VXXfdpTNnzpQ7T1pamkJDQ71Ly5Yta6J9AMBVLMAYY2pkQwEBWrdunYYMGXJZ9W+99ZbGjh2rDRs2KCEhody6/Px8RUdHa/78+RozZoy1pri4WMXFxd7HHo/np5DcJalJZfYCuIpEH6jtDgA/OiOpqwoKCuR0Ov2yBb9+BllVq1at0iOPPKI1a9ZUGI6SFBYWpptvvln79u0rt8bhcMjhcFR3mwCAa1ide4t15cqVSk5O1sqVKzVw4MBL1hcWFmr//v2KjIysge4AAPWFX19BFhYW+ryyy83N1Y4dO9SsWTO1atVKqampOnLkiFasWCHpp7dVR40apd/97neKi4uT2+2WJDVq1EihoaGSpGeffVaDBg1SdHS0jh49qmnTpikoKEjDhw/3564AAOoZv76C/PLLL9WjRw/vJRopKSnq0aOHpk6dKkk6duyYzxmor732mi5cuKDHHntMkZGR3uWpp57y1hw+fFjDhw9Xx44d9cADD+iGG27Q559/rubNm/tzVwAA9UyNnaRTl3g8np9ekXKSDq5lnKSDa5r/T9Kpc59BAgBQFxCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFgQkAAAWBCQAABYEJAAAFj4NSA//vhjDRo0SFFRUQoICND69esrrM/KylJAQECZxe12+9Slp6erdevWCgkJUVxcnLZu3erHvQAA1Ed+DciioiJ1795d6enplVpvz549OnbsmHdp0aKF97nVq1crJSVF06ZN07Zt29S9e3clJibq+PHj1d0+AKAea+DPyQcMGKABAwZUer0WLVooLCzM+tz8+fM1duxYJScnS5IWLlyo9957T0uWLNHkyZOt6xQXF6u4uNj7uKCg4KcfCivdGnAVOVPbDQB+9NMfcGOM37bg14CsqtjYWBUXF6tr166aPn26fvGLX0iSzp07p5ycHKWmpnprAwMDlZCQoOzs7HLnS0tL04wZM8o+cXu1tw7UIV1ruwHA706dOqXQ0FC/zF2nAjIyMlILFy5Ur169VFxcrNdff119+/bVli1bdOutt+rkyZMqKSlRRESEz3oRERH69ttvy503NTVVKSkp3sf5+fmKjo7WwYMH/XZg/cHj8ahly5Y6dOiQnE5nbbdz2a7WvqWrt3f6rln0XfMKCgrUqlUrNWvWzG/bqFMB2bFjR3Xs2NH7+I477tD+/fv10ksv6X/+53+qPK/D4ZDD4SgzHhoaetX9UkiS0+mk7xp2tfZO3zWLvmteYKD/TqWp85d59O7dW/v27ZMkhYeHKygoSHl5eT41eXl5crlctdEeAOAaVecDcseOHYqMjJQkBQcHq2fPnsrMzPQ+X1paqszMTMXHx9dWiwCAa5Bf32ItLCz0vvqTpNzcXO3YsUPNmjVTq1atlJqaqiNHjmjFihWSpAULFqhNmzbq0qWLfvzxR73++uv68MMPtWnTJu8cKSkpGjVqlHr16qXevXtrwYIFKioq8p7VejkcDoemTZtmfdu1LqPvmne19k7fNYu+a15N9B5g/HiObFZWlu65554y46NGjdKyZcs0evRofffdd8rKypIkzZ07V6+99pqOHDmixo0bq1u3bpo6dWqZOV555RW9+OKLcrvdio2N1csvv6y4uDh/7QYAoB7ya0ACAHC1qvOfQQIAUBsISAAALAhIAAAsCEgAACyuyYA8ffq0RowYIafTqbCwMI0ZM0aFhRV/M3nfvn3L3Gbr0Ucf9ak5ePCgBg4cqMaNG6tFixaaOHGiLly4UKu9nz59Wk888YQ6duyoRo0aqVWrVnryySf/8YXs/z/bbcRWrVpV5T4re8uxNWvWqFOnTgoJCVFMTIw2btzo87wxRlOnTlVkZKQaNWqkhIQE7d27t8r9VUffixYt0l133aWmTZuqadOmSkhIKFM/evToMsc1KSmpVvtetmxZmZ5CQkJ8amrqeFe2d9u/w4CAAA0cONBb4+9jXtnb9Ek/nbF/6623yuFwqH379lq2bFmZmpq4TV9le1+7dq3uvfdeNW/eXE6nU/Hx8Xr//fd9aqZPn17meHfq1KlW+66xWyOaa1BSUpLp3r27+fzzz83//u//mvbt25vhw4dXuE6fPn3M2LFjzbFjx7xLQUGB9/kLFy6Yrl27moSEBLN9+3azceNGEx4eblJTU2u19507d5pf/epX5p133jH79u0zmZmZpkOHDub+++/3qZNkli5d6rN/P/zwQ5V6XLVqlQkODjZLliwxX3/9tRk7dqwJCwszeXl51vpPP/3UBAUFmblz55pvvvnGPP/886Zhw4Zm586d3prZs2eb0NBQs379evO3v/3N/Ou//qtp06ZNlXusjr4ffPBBk56ebrZv3252795tRo8ebUJDQ83hw4e9NaNGjTJJSUk+x/X06dPV1nNV+l66dKlxOp0+Pbndbp+amjjeVen91KlTPn3v2rXLBAUFmaVLl3pr/H3MN27caP7f//t/Zu3atUaSWbduXYX1f//7303jxo1NSkqK+eabb8zvf/97ExQUZDIyMrw1lT0ONdX7U089ZebMmWO2bt1q/u///s+kpqaahg0bmm3btnlrpk2bZrp06eJzvE+cOFGrfX/00UdGktmzZ49PXyUlJd6a6jjm11xAfvPNN0aS+eKLL7xjf/nLX0xAQIA5cuRIuev16dPHPPXUU+U+v3HjRhMYGOjzh+bVV181TqfTFBcX12rv/+ztt982wcHB5vz5896xy/mlu1y9e/c2jz32mPdxSUmJiYqKMmlpadb6Bx54wAwcONBnLC4uzvznf/6nMcaY0tJS43K5zIsvvuh9Pj8/3zgcDrNy5cpq6bkqff+zCxcumCZNmpjly5d7x0aNGmUGDx5cbT3aVLbvpUuXmtDQ0HLnq6njbcyVH/OXXnrJNGnSxBQWFnrHauKYX3Q5/26ee+4506VLF5+xoUOHmsTERO/jKz0OVVHVf/OdO3c2M2bM8D6eNm2a6d69e/U1dgmVCcjvv/++3JrqOObX3Fus2dnZCgsLU69evbxjCQkJCgwM1JYtWypc980331R4eLi6du2q1NRUnT171mfemJgYnzuJJCYmyuPx6Ouvv6713n+uoKBATqdTDRr4flHSY489pvDwcPXu3VtLliyp0n3ULt5yLCEhwTt2qVuOZWdn+9RLPx27i/W5ublyu90+NaGhoYqLi6vwNmb+7vufnT17VufPny9z94CsrCy1aNFCHTt21Pjx43Xq1Klq6flK+i4sLFR0dLRatmypwYMH+/yO1sTxvpLef27x4sUaNmyYrrvuOp9xfx7zyrrU73d1HIeaUlpaqjNnzpT5Hd+7d6+ioqLUtm1bjRgxQgcPHqylDn3FxsYqMjJS9957rz799FPveHUd8zp1N4/q4Ha71aJFC5+xBg0aqFmzZmXen/65Bx98UNHR0YqKitJXX32lSZMmac+ePVq7dq13Xtttti4+V5u9/9zJkyc1a9YsjRs3zmd85syZ+uUvf6nGjRtr06ZN+vWvf63CwkI9+eSTleqxKrccK+/YXdyni/+tqOZKVfVWaT83adIkRUVF+fyjS0pK0q9+9Su1adNG+/fv129+8xsNGDBA2dnZCgoKqpW+O3bsqCVLlqhbt24qKCjQvHnzdMcdd+jrr7/WTTfdVCPHu6q9/9zWrVu1a9cuLV682Gfc38e8ssr7/fZ4PPrhhx/0/fffX/HvXk2ZN2+eCgsL9cADD3jH4uLitGzZMnXs2FHHjh3TjBkzdNddd2nXrl1q0qRJrfTpr1sj/rOrJiAnT56sOXPmVFize/fuKs//80CJiYlRZGSk+vXrp/3796tdu3ZVnlfyf+8XeTweDRw4UJ07d9b06dN9npsyZYr35x49eqioqEgvvvhipQOyvpo9e7ZWrVqlrKwsnxNehg0b5v05JiZG3bp1U7t27ZSVlaV+/frVRquKj4/3+fL+O+64Q7fccov++Mc/atasWbXSU1UsXrxYMTEx6t27t894XTzm14K33npLM2bM0IYNG3z+R33AgAHen7t166a4uDhFR0fr7bff1pgxY2qjVb/dGvGfXTUBOWHCBI0ePbrCmrZt28rlcun48eM+4xcuXNDp06crdUusi9/tum/fPrVr104ul6vMGVAXb7t1qXlrovczZ84oKSlJTZo00bp169SwYcMK6+Pi4jRr1iwVFxdX6st+q3LLMZfLVWH9xf/m5eV579xy8XFsbOxl91bdfV80b948zZ49Wx988IG6detWYW3btm0VHh6uffv2Vcsf6+q4xVvDhg3Vo0cP740DauJ4S1fWe1FRkVatWqWZM2decjvVfcwrq7zfb6fTqUaNGikoKKjO36Zv1apVeuSRR7RmzZoybxf/s7CwMN18880+N6KoC3r37q1PPvlEUvXdGvGq+QyyefPm6tSpU4VLcHCw4uPjlZ+fr5ycHO+6H374oUpLSyv1heY7duyQJO8fkPj4eO3cudMnwDZv3iyn06nOnTvXau8ej0f9+/dXcHCw3nnnnTKn9Je3f02bNq30N+FX5ZZj8fHxPvXST8fuYn2bNm3kcrl8ajwej7Zs2VJttzGr6q3S5s6dq1mzZikjI8Pns+HyHD58WKdOnfIJntro++dKSkq0c+dOb081cbyvtPc1a9aouLhYDz300CW3U93HvLIu9ftd12/Tt3LlSiUnJ2vlypU+l9OUp7CwUPv376+1410ev9wa8bJP57mKJCUlmR49epgtW7aYTz75xHTo0MHnUonDhw+bjh07mi1bthhjjNm3b5+ZOXOm+fLLL01ubq7ZsGGDadu2rbn77ru961y8zKN///5mx44dJiMjwzRv3twvl3lUpveCggITFxdnYmJizL59+3xOeb5w4YIxxph33nnHLFq0yOzcudPs3bvX/OEPfzCNGzc2U6dOrVKPq1atMg6Hwyxbtsx88803Zty4cSYsLMx7hu/DDz9sJk+e7K3/9NNPTYMGDcy8efPM7t27zbRp06yXeYSFhZkNGzaYr776ygwePNgvl3lUpu/Zs2eb4OBg86c//cnnuJ45c8YYY8yZM2fMs88+a7Kzs01ubq754IMPzK233mo6dOhgfvzxx1rre8aMGeb99983+/fvNzk5OWbYsGEmJCTEfP311z775u/jXZXeL7rzzjvN0KFDy4zXxDE/c+aM2b59u9m+fbuRZObPn2+2b99uDhw4YIwxZvLkyebhhx/21l+8zGPixIlm9+7dJj093XqZR0XHobpUtvc333zTNGjQwKSnp/v8jufn53trJkyYYLKyskxubq759NNPTUJCggkPDzfHjx+vtb5feukls379erN3716zc+dO89RTT5nAwEDzwQcfeGuq45hfkwF56tQpM3z4cHP99dcbp9NpkpOTvX/UjDEmNzfXSDIfffSRMcaYgwcPmrvvvts0a9bMOBwO0759ezNx4kSf6yCNMea7774zAwYMMI0aNTLh4eFmwoQJPpdS1EbvF093ti25ubnGmJ8uFYmNjTXXX3+9ue6660z37t3NwoULfa4Zqqzf//73plWrViY4ONj07t3bfP75597n+vTpY0aNGuVT//bbb5ubb77ZBAcHmy5dupj33nvP5/nS0lIzZcoUExERYRwOh+nXr5/Zs2dPlfurjr6jo6Otx3XatGnGGGPOnj1r+vfvb5o3b24aNmxooqOjzdixY6v9j15l+3766ae9tREREea+++7zua7NmJo73pXt3Rhjvv32WyPJbNq0qcxcNXHMy/s3dbHPUaNGmT59+pRZJzY21gQHB5u2bdv6XLd5UUXHobZ679OnT4X1xvx0yUpkZKQJDg42N954oxk6dKjZt29frfY9Z84c065dOxMSEmKaNWtm+vbtaz788MMy817pMed2VwAAWFw1n0ECAFCTCEgAACwISAAALAhIAAAsCEgAACwISAAALAhIAAAsCEgAACwISAAALAhIAAAsCEgAACz+P7O8lF1NtvFVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tensor로 인덱싱\n",
    "a = torch.tensor([1,2,3,4,5])\n",
    "A = a[2]\n",
    "print(A)\n",
    "A = a[torch.tensor(2)] # torch.tensor를 안에다가?\n",
    "print(A)\n",
    "A = a[torch.tensor([2,3,4])]\n",
    "print(A)\n",
    "A = a[ torch.tensor([[2,2,2], [3,3,3]]) ]\n",
    "print(A) # 인덱싱된 애들로 2행 3열 짜리 행렬을 생성\n",
    "\n",
    "a = torch.tensor([1,2,3])\n",
    "print(a[torch.tensor([[1,1,1], [2,2,2]])])\n",
    "# print(a[[1,1,1], [2,2,2]]) # 리스트 인덱싱과 다름!\n",
    "\n",
    "a = torch.tensor([[1,2,3], [4,5,6]])\n",
    "print(a[ torch.tensor(0) ])\n",
    "A = a[ torch.tensor([[0,1], [1,1]]) ]\n",
    "print(A.shape) # 예를 들어, a[0] = tensor([1,2,3])과 같이 1차원 데이터 이므로 한 차원이 뒤에 늘어나서 2,2 \"3\"이 된다!\n",
    "print(A)\n",
    "\n",
    "# segmentation 결과 그림 보여줄 때 사용!\n",
    "b = torch.tensor([[225,225,0], [0,225,0], [0,0,225], [225,0,225], [70,80,75], [0,0,4], [60,100,255]])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(b[ torch.tensor([[0,2], [1,2]]) ]) # 2,2,3 행렬이므로 잘 바꿔보며 이해해보자 근데 색도 그렇고 뭐가 다른데"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 6],\n",
      "        [3, 4, 7],\n",
      "        [5, 6, 2],\n",
      "        [7, 8, 9]])\n",
      "torch.Size([4, 3])\n",
      "tensor(2)\n",
      "tensor([8, 6, 7, 3, 5])\n",
      "tensor([[1, 2],\n",
      "        [8, 3]])\n",
      "tensor([2, 6, 2, 8])\n",
      "tensor([2, 2])\n",
      "tensor([2, 6])\n",
      "tensor([[3, 4, 7],\n",
      "        [3, 4, 7],\n",
      "        [5, 6, 2],\n",
      "        [5, 6, 2],\n",
      "        [5, 6, 2]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1,2,6], [3,4,7], [5,6,2], [7,8,9]])\n",
    "print(A)\n",
    "print(A.shape)\n",
    "\n",
    "# 1. A[몇 행인가, 몇 열인가]\n",
    "print(A[0,1])\n",
    "# 2-1. A[[몇 행인가, 몇 행인가], [몇 열인가, 몇 열인가]]\n",
    "print(A[[3,2,3,1,2], [1,1,0,0,0]])\n",
    "# 2-2. A[ [[몇 행인가, 몇 행인가]], [[몇 열인가, 몇 열인가]] ] => 결과가 행렬 형태가 되도록 인덱싱!\n",
    "print(A[ [[0,2], [3,1]], [[0,2], [1,0]] ])\n",
    "# 3. A[ tensor(bool) ] => A와 같은 shape를 가지는 tensor형 bool이 어디에 True를 가지고 있나\n",
    "print(A[ torch.tensor([[False, True, True], [False, False, False], [False, False, True], [False, True, False]]) ])\n",
    "print(A[A==2]) # 마스킹같은 걸 할 수 있다.\n",
    "# 4. A[몇 번째 값에 True가 있나, 몇 번째 값에 True가 있나]\n",
    "print(A[[True, False, False, False], [False, True, True]])\n",
    "# 5. A[ tensor ] => 몇 번째 것을 어떻게 쌓을거냐\n",
    "print(A[ torch.tensor([1,1,2,2,2]) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch의 여러 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0611, -0.0685,  0.3081],\n",
      "        [-2.4149, -1.4832, -0.6462],\n",
      "        [ 0.0664, -1.8620,  0.6854]])\n",
      "tensor([[0.8424, 0.0934, 0.8540],\n",
      "        [0.6922, 0.7105, 0.2165],\n",
      "        [0.4931, 0.0473, 0.5032]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3,3) # Normal 의 n # Normal -> 평균 0, 표준편차 1인 정규분포에서 랜덤하게 뽑아라 가우시안 분포\n",
    "B = torch.rand(3,3) # 이건 uniform - 0-1 사이의 균일한 분포에서 랜덤하게 뽑아라\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6413, -0.1053,  0.6421],\n",
      "        [-0.9485,  0.3111, -0.9676],\n",
      "        [-1.8606,  0.4180,  0.1826]])\n",
      "tensor([[0.6413, 0.1053, 0.6421],\n",
      "        [0.9485, 0.3111, 0.9676],\n",
      "        [1.8606, 0.4180, 0.1826]])\n",
      "tensor([[0.8008, 0.3245, 0.8013],\n",
      "        [0.9739, 0.5577, 0.9837],\n",
      "        [1.3641, 0.6465, 0.4273]])\n",
      "tensor([[0.5266, 0.9000, 1.9005],\n",
      "        [0.3873, 1.3649, 0.3800],\n",
      "        [0.1556, 1.5189, 1.2004]])\n",
      "tensor([[-0.4443, -2.2508, -0.4430],\n",
      "        [-0.0528, -1.1678, -0.0329],\n",
      "        [ 0.6209, -0.8723, -1.7004]])\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor([[-1., -0.,  1.],\n",
      "        [-1.,  0., -1.],\n",
      "        [-2.,  0.,  0.]])\n",
      "tensor([[-0.6400, -0.1100,  0.6400],\n",
      "        [-0.9500,  0.3100, -0.9700],\n",
      "        [-1.8600,  0.4200,  0.1800]])\n",
      "tensor([[-1., -1.,  0.],\n",
      "        [-1.,  0., -1.],\n",
      "        [-2.,  0.,  0.]])\n",
      "tensor([[-0., -0.,  1.],\n",
      "        [-0.,  1., -0.],\n",
      "        [-1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3,3)\n",
    "print(A)\n",
    "print(torch.abs(A)) # 절댓값\n",
    "print(torch.sqrt(torch.abs(A))) # 절댓값 씌우고 루트 씌우기\n",
    "print(torch.exp(A)) # 지수함수\n",
    "print(torch.log(torch.abs(A))) # 로그함수\n",
    "print(torch.log(torch.exp(torch.tensor(1)))) # torch.exp(torch.tensor(1)) = e^1 = 2.7182817459106445 # e^1에 로그 씌우면 1이 나온다. # 로그함수의 역함수?\n",
    "print(torch.log10(torch.tensor(10))) # 10을 밑으로 하는 로그함수\n",
    "print(torch.log2(torch.tensor(2))) # 2를 밑으로 하는 로그함수\n",
    "print(torch.round(A)) # 반올림\n",
    "print(torch.round(A, decimals=2)) # 소수점 둘째자리까지 반올림\n",
    "print(torch.floor(A)) # 내림\n",
    "print(torch.ceil(A)) # 올림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n",
      "tensor(0.5000)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.sin(torch.tensor(torch.pi/6))) # type(torch.pi) -> float임 만약 tensor와 연산하면 tensor로 바꿔줌 # torch.tensor(torch.pi)로 바꿔주면 됨?\n",
    "print(torch.cos(torch.tensor(torch.pi/3)))\n",
    "print(torch.tan(torch.tensor(torch.pi/4)))\n",
    "print(torch.tanh(torch.tensor(-10)))\n",
    "\n",
    "type(torch.tensor(1)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan)\n",
      "tensor([False, False,  True, False, False])\n",
      "tensor([False, False, False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "torch.nan # nan a number\n",
    "print(torch.log(torch.tensor(-1)))\n",
    "print(torch.isnan(torch.tensor([1,2,torch.nan,3,4])))\n",
    "print(torch.isinf(torch.tensor([1,2,3,4,torch.inf])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0035,  0.2626,  1.7261, -0.5705],\n",
      "        [-0.2509,  0.4975, -0.4204, -0.2696],\n",
      "        [-0.4929,  0.0964,  0.2491, -0.6385]])\n",
      "tensor(1.7261)\n",
      "torch.return_types.max(\n",
      "values=tensor([-0.2509,  0.4975,  1.7261, -0.2696]),\n",
      "indices=tensor([1, 1, 0, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([1.7261, 0.4975, 0.2491]),\n",
      "indices=tensor([2, 1, 2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([[-0.2509,  0.4975,  1.7261, -0.2696]]),\n",
      "indices=tensor([[1, 1, 0, 1]]))\n",
      "torch.return_types.max(\n",
      "values=tensor([[1.7261],\n",
      "        [0.4975],\n",
      "        [0.2491]]),\n",
      "indices=tensor([[2],\n",
      "        [1],\n",
      "        [2]]))\n",
      "tensor(-1.0035)\n",
      "torch.return_types.min(\n",
      "values=tensor([-1.0035,  0.0964, -0.4204, -0.6385]),\n",
      "indices=tensor([0, 2, 1, 2]))\n",
      "torch.return_types.min(\n",
      "values=tensor([-1.0035, -0.4204, -0.6385]),\n",
      "indices=tensor([0, 2, 3]))\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor([1, 1, 0, 1])\n",
      "tensor([2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3,4)\n",
    "print(A)\n",
    "print(torch.max(A))\n",
    "print(torch.max(A,dim=0)) # 0번째 차원에서 최대값을 찾아라\n",
    "print(torch.max(A,dim=1)) # 1D tensor로 바꿔서 최대값과 그 인덱스를 반환\n",
    "print(torch.max(A,dim=0, keepdim=True)) # 차원 유지\n",
    "print(torch.max(A,dim=1, keepdim=True)) # 3행 1열  2D tensor로 반환\n",
    "print(torch.min(A))\n",
    "print(torch.min(A,dim=0))\n",
    "print(torch.min(A,dim=1))\n",
    "print(torch.argmax(A))\n",
    "print(torch.argmax(A))\n",
    "print(torch.argmax(A,dim=0)) # 각 열에서 가장 큰 애가 존재하는 인덱스\n",
    "print(torch.argmax(A,dim=1)) # 각 열에서 가장 큰 애가 존재하는 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.sort(\n",
      "values=tensor([[ 1.3709],\n",
      "        [ 0.4429],\n",
      "        [ 0.1528],\n",
      "        [ 0.0136],\n",
      "        [-0.1982],\n",
      "        [-1.2305]]),\n",
      "indices=tensor([[5],\n",
      "        [1],\n",
      "        [3],\n",
      "        [4],\n",
      "        [2],\n",
      "        [0]]))\n",
      "tensor(1.3709)\n",
      "tensor(1.3709)\n",
      "tensor([[1.2305],\n",
      "        [0.4429],\n",
      "        [0.1982],\n",
      "        [0.1528],\n",
      "        [0.0136],\n",
      "        [1.3709]])\n",
      "tensor([[1.2305],\n",
      "        [0.4429],\n",
      "        [0.1982],\n",
      "        [0.1528],\n",
      "        [0.0136],\n",
      "        [1.3709]])\n"
     ]
    }
   ],
   "source": [
    "# a = torch.randn(6,1)\n",
    "# print(a)\n",
    "# a_sorted = torch.sort(a, dim=0)\n",
    "# print(a_sorted) # 정렬된 값과 그 인덱스를 반환\n",
    "\n",
    "a = torch.randn(6,1)\n",
    "# print(a)\n",
    "# print(a.sort(dim=0)) # 위와 같은 결과 # 근데 정확하게 뭐가 다르지\n",
    "print(a.sort(dim=0, descending=True)) # 내림차순\n",
    "\n",
    "print(torch.max(a)) # 아래는 같은 작용이다\n",
    "print(a.max())\n",
    "print(torch.abs(a))\n",
    "print(a.abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3312, -0.2255, -0.1987, -0.0268],\n",
      "        [-0.4820,  0.3932, -0.8944,  0.8200],\n",
      "        [ 0.1583, -2.7703, -0.8363,  0.1500]])\n",
      "tensor(-3.5812)\n",
      "tensor([-0.1198, -0.1631, -3.2982])\n",
      "tensor([[-0.1198],\n",
      "        [-0.1631],\n",
      "        [-3.2982]])\n",
      "tensor(-0.2984)\n",
      "tensor([-0.0299, -0.0408, -0.8246])\n",
      "tensor([[-0.0299],\n",
      "        [-0.0408],\n",
      "        [-0.8246]])\n",
      "tensor(0.9250)\n",
      "tensor([[-0.1198],\n",
      "        [-0.1631],\n",
      "        [-3.2982]])\n",
      "tensor([[-0.0299],\n",
      "        [-0.0408],\n",
      "        [-0.8246]])\n",
      "tensor(0.9250)\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3,4)\n",
    "print(A)\n",
    "print(torch.sum(A))\n",
    "print(torch.sum(A, dim=1))\n",
    "print(torch.sum(A, dim=1, keepdim=True))\n",
    "print(torch.mean(A))\n",
    "print(torch.mean(A, dim=1))\n",
    "print(torch.mean(A, dim=1, keepdim=True))\n",
    "print(torch.std(A)) # standard deviation 표준 편차\n",
    "\n",
    "print(A.sum(dim=1, keepdim=True))\n",
    "print(A.mean(dim=1, keepdim=True))\n",
    "print(A.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 2, 2, 4, 2, 4, 3, 1, 1, 1, 1, 1])\n",
      "torch.Size([12])\n",
      "tensor([[[4, 2, 2],\n",
      "         [4, 2, 4]],\n",
      "\n",
      "        [[3, 1, 1],\n",
      "         [1, 1, 1]]])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# reshape 굉장히중요\n",
    "A = torch.randint(1,5,size=(12,)) # 1부터 5미만 12개 정수를 랜덤하게 (1차원은 (N, )로 표현)\n",
    "print(A)\n",
    "print(A.shape)\n",
    "# reshape\n",
    "B = A.reshape(2,2,3) # 2x2x3 행렬로 바꿔라 size=(2,2,3)도 가능?\n",
    "print(B)\n",
    "print(B.ndim) # 3차원 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]])\n",
      "torch.Size([4, 5])\n",
      "torch.Size([2, 5, 2])\n",
      "torch.Size([2, 2, 5])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(20,)\n",
    "print(A)\n",
    "print(A.reshape(4,5))\n",
    "print(A.reshape(4,-1).shape) # 4개 행이 되도록 열의 수를 맞춰준다!\n",
    "print(A.reshape(2,5,-1).shape)\n",
    "print(A.reshape(2,-1,5).shape)\n",
    "print(A.reshape(1,-1).shape) # 2차원 행 벡터\n",
    "print(A.reshape(-1,1).shape) # 2차원 열 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor([[9]])\n",
      "tensor([[9]])\n",
      "tensor([[9]])\n",
      "tensor([[9]])\n",
      "torch.Size([4, 6, 3])\n",
      "torch.Size([4, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([2,2,1])\n",
    "print(torch.sum(a*b))\n",
    "\n",
    "a = a.reshape(3,1)\n",
    "b = b.reshape(3,1)\n",
    "print(a.transpose(1,0)@b)\n",
    "print(a.permute(1,0)@b)\n",
    "print(a.T@b)\n",
    "print(a.t()@b)\n",
    "\n",
    "A = torch.randn(4,3,6)\n",
    "print(A.permute(0,2,1).shape) # 4x6x3 행렬로 바꿔라\n",
    "print(A.transpose(2,1).shape) # 4x6x3 행렬로 바꿔라 # transpose는 2개의 차원만 바꿀 수 있음 - 둘끼리 자리 교체만 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 6])\n",
      "torch.Size([4, 5, 6])\n",
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([3, 4, 6])\n",
      "torch.Size([3, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,4,5,6)\n",
    "print(x[1,2,:,:,:].shape)\n",
    "print(x[1,2,...].shape) # x[1, 2, ...]는 x[1, 2, :, :, :]와 같다\n",
    "print(x[:,:,:,:,3].shape)\n",
    "print(x[...,3].shape) # x[...,3]은 x[:,:,:,:,3]과 같다\n",
    "print(x[1,:,:,3,:].shape)\n",
    "print(x[1,...,3,:].shape) # x[1, ..., 3, :]은 x[1, :, :, 3, :]과 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(3,4)\n",
    "B = torch.zeros(3,4)\n",
    "C = torch.vstack([A,B])\n",
    "D = torch.hstack([A,B]) # v는 0번째 차원, h는 1번째 차원에 쌓는다. (A,B 사이즈 (2,3,4)로 추가 해보기)\n",
    "E = torch.cat([A,B], dim=0)\n",
    "F = torch.cat([A,B], dim=1) # concatematation: 연결 # vstack과 hstack과 같은 결과\n",
    "\n",
    "print(C)\n",
    "print(D)\n",
    "print(E)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 3, 1, 4, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(1,1,1,3,1,1,1,4,1,1,1)\n",
    "# print(A)\n",
    "print(A.shape)\n",
    "print(A.squeeze().shape)\n",
    "print(A.squeeze(dim=(0,2,4,5)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([3, 4, 1])\n",
      "torch.Size([1, 3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3,4)\n",
    "print(A.unsqueeze(dim=0).shape)\n",
    "print(A.unsqueeze(dim=1).shape)\n",
    "print(A.unsqueeze(dim=2).shape) \n",
    "print(A.reshape(1,3,4).shape)\n",
    "print(A.reshape(3,1,4).shape)\n",
    "print(A.reshape(3,4,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(3,4)\n",
    "B = torch.zeros(3,4)\n",
    "A = A.unsqueeze(dim=0)\n",
    "B = B.unsqueeze(dim=0)\n",
    "C = torch.cat([A,B], dim=0)\n",
    "print(C)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(3,4)\n",
    "B = torch.zeros(3,4)\n",
    "C = torch.stack([A,B])\n",
    "print(C) # unsqueeze 안하고 stack으로 하면 되긴 하다. (차원을 추가(default는 dim=0에)해서 쌓아준다.)\n",
    "# 근데 차원을 추가해서 쌓는 방식이라 A,B shape이 일치해야 한다. concat은 달라도 쌓을 차원 이외 차원들만 맞으면 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100,   2],\n",
      "        [  3,   4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1,2], [3,4]])\n",
    "B = A.clone()\n",
    "B[0,0] = 100\n",
    "\n",
    "print(B)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@에 대해 좀만 더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([32, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(5,7)\n",
    "B = torch.randn(7,10)\n",
    "C = A@B\n",
    "print(C.shape)\n",
    "\n",
    "A = torch.randn(32,5,7)\n",
    "B = torch.randn(32,7,10)\n",
    "C = A@B\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(32,5,7)\n",
    "B = torch.randn(7,10)\n",
    "\n",
    "C = A@B\n",
    "print(C.shape)\n",
    "\n",
    "# 강사 필기용 (repeat는 좀 지엽적인듯하다?)\n",
    "# D = A@B.repeat(32,1,1)\n",
    "# print(D.shape)\n",
    "# print((C-D).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 강사 필기용\n",
    "# A = torch.rand(2,3)\n",
    "# A_repeat = A.repeat(3,1,3,2)\n",
    "# print(A)\n",
    "# print(A_repeat)\n",
    "# print(A_repeat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy <-> torch 서로 전환가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = torch.tensor([1,2,3])\n",
    "A = torch.tensor(a) # A = torch.from_numpy(a)\n",
    "B = b.numpy() # B = np.array(b)\n",
    "print(type(A))\n",
    "print(type(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝을 가능케 한 autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.], requires_grad=True) # float 이여야 해서 1.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "False\n",
      "tensor([1.], requires_grad=True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.])\n",
    "print(x)\n",
    "print(x.requires_grad)\n",
    "\n",
    "x.requires_grad=True\n",
    "print(x)\n",
    "print(x.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
