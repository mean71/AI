{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R1ybKJ7JUK7"
      },
      "source": [
        "### Pytorch 설치 및 확인\n",
        "\n",
        "매번 설치/확인 다시 해줘야 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYC7h8bMATYj",
        "outputId": "3675269d-0aa7-4006-dd77-23919bfbbfdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.4.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from torch) (74.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_C7Xg6KJjm7",
        "outputId": "5a3be64b-392c-4970-9863-2e5c55537f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4.1+cpu\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXrU-O7_OsSz"
      },
      "source": [
        "### 데이터 업로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGUCk8UUp7On"
      },
      "source": [
        "다음 파일을 다운로드합니다.\n",
        "\n",
        "https://download.pytorch.org/tutorial/data.zip\n",
        "\n",
        "어떤 형식으로 데이터가 저장되어 있는지 한번 열어서 읽어보세요.\n",
        "\n",
        "왼쪽 바 폴더모양 (files) 클릭 후 코랩에서 쓸 수 있도록 언어별 이름 데이터를 업로드해주세요.\n",
        "\n",
        "`names/` 폴더를 만든 후 그 안에 집어넣습시다.\n",
        "\n",
        "텍스트 파일을 클릭해서 정상적으로 업로드 되었는지 내용을 확인합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBQlK5MYOx39"
      },
      "source": [
        "### `glob`으로 데이터 읽기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYH1iMM6tQ7n"
      },
      "source": [
        "`glob`은 패턴 매칭을 통해 디스크에 어떤 파일이 있는지 파일명을 읽어옵니다.\n",
        "\n",
        "우리가 사용할 데이터 목록인 18개 국어 각각의 파일명을 읽어옵시다.\n",
        "\n",
        "이후 파이썬 내장 파일 입출력 기능으로 파일을 읽어옵시다.\n",
        "\n",
        "읽어온 데이터는 다음 변수에 저장해둡시다.\n",
        "\n",
        "모든 이름은 알파벳 소문자만 사용해서 저장해둡시다.\n",
        "\n",
        "`category_names: dict[str, list[str]]`\n",
        "\n",
        "`all_categories: list[str]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMn0awJ1o5Rd",
        "outputId": "b0c7f9bd-a044-4a10-cd53-b3e59a2d0323"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "files = glob.glob('names/*.txt')\n",
        "assert len(files) == 18\n",
        "print(files)\n",
        "\n",
        "category_names = {}\n",
        "all_categories = []\n",
        "all_letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "n_letters = len(all_letters)\n",
        "assert n_letters == 26\n",
        "\n",
        "for file in files:\n",
        "    with open(file) as f:\n",
        "        names = f.read().strip().split('\\n')\n",
        "\n",
        "    lang = file.split('/')[-1].split('.')[0]\n",
        "    all_categories.append(lang)\n",
        "\n",
        "    names = [n.lower() for n in names] # Make everything lowercases\n",
        "    names = [''.join([c for c in n if c in all_letters]) for n in names] # Ignore non-alphabet letters\n",
        "    category_names[lang] = names\n",
        "\n",
        "    print(f'{lang}: {len(names)} |', names[0], names[1], names[2])\n",
        "\n",
        "n_categories = len(all_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8LJktQ2O3H7"
      },
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbNJlDZmwwEf"
      },
      "source": [
        "각 이름을 텐서로 변환하는 방법입니다. 알단은 변환 함수만 정의해둡니다.\n",
        "\n",
        "하나의 알파벳 문자를 \"one-hot vector\" 방식으로 표상합시다. 보다 구체적으로는 다음과 같습니다.\n",
        "\n",
        "```\n",
        "a -> <1 0 0 0 ... 0>\n",
        "b -> <0 1 0 0 ... 0>\n",
        "...\n",
        "z -> <0 0 0 0 ... 1>\n",
        "```\n",
        "\n",
        "문자 하나가 아닌 단어 하나는 (line_length, n_letters)이라는 shape를 갖는 텐서로 변환됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zq0_KnLzn6M",
        "outputId": "2ee7553c-52bc-41ab-c8a9-66b7ea51c59f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Find letter index from all_letters, e.g. \"a\" = 0\n",
        "def letterToIndex(letter):\n",
        "    return all_letters.find(letter.lower())\n",
        "\n",
        "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
        "def letterToTensor(letter):\n",
        "    tensor = torch.zeros(1, n_letters)\n",
        "    tensor[0][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "# Turn a line into a <line_length x 1 x n_letters>,\n",
        "# or an array of one-hot letter vectors\n",
        "def lineToTensor(line):\n",
        "    tensor = torch.zeros(len(line), n_letters)\n",
        "    for li, letter in enumerate(line):\n",
        "        tensor[li][letterToIndex(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "print(letterToTensor('c'))\n",
        "\n",
        "print(lineToTensor('cat').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yczj030iMZZA"
      },
      "source": [
        "### Softmax\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7MqIAieHZEA",
        "outputId": "f366b275-2220-47c6-bf26-5985ba3a6ed4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "aaa = torch.rand(4)\n",
        "print(aaa)\n",
        "print(torch.softmax(aaa, -1))\n",
        "print(torch.sum(torch.softmax(aaa, -1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDpOiaYgQPQv"
      },
      "source": [
        "softmax 레이어를 통과하면, 어떠한 값이든 확률 값으로 변하게 됩니다.\n",
        "\n",
        "위 예시 코드에서, 랜덤 값인 `aaa`가 softmax 레이어를 통과했더니 확률값으로 변화했다는 점을 관찰하세요. 입력값인 원래의 `aaa`에 저장되어 있던 값이 더 클수록 더 큰 확률값으로 변하게 됩니다. 이 값이 확률값이라는 점은 더했을 때 1이 된다는 점에서 알 수 있습니다.\n",
        "\n",
        "신경망의 마지막 레이어의 값을 해석하기 위하여, 보통 마지막 레이어에 softmax를 넣어두는 경우가 많습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRZd-qXCQTam"
      },
      "source": [
        "### `dim` parameter (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV9u2NKnIV-v"
      },
      "source": [
        "본 섹션은 어렵지만 중요한 내용을 다룹니다. `torch.sum`, `torch.max` 등 수많은 함수에서 똑같이 사용되는 내용입니다. Softmax를 예시로 들어 설명하겠습니다.\n",
        "\n",
        "`torch.softmax(aaa, -1)`에서 적용할 `-1`은 텐서 차원의 인덱스입니다. 이 값을 이해하기 위해 예시를 들겠습니다.\n",
        "\n",
        "예를 들어, shape가 (2, 3)인 텐서에 softmax를 적용하고 싶다면 어떻게 해야 할까요?\n",
        "\n",
        "```\n",
        "mat =\n",
        "[[231, 252, 419]\n",
        " [434, 593, 321]]\n",
        "(예시를 위한 랜덤값입니다)\n",
        "```\n",
        "\n",
        "각 행마다 softmax를 적용해서 각 행의 합을 1로 만들 수도 있고 (이렇게 하면 행렬 원소의 총 합은 2가 됩니다) 각 열마다 softmax를 적용해서 각 열의 합을 1으로 만들 수도 있습니다 (이렇게 하면 행렬 원소의 총 합은 3이 됩니다).\n",
        "\n",
        "각 행마다 softmax를 적용하고 싶으면 `torch.softmax(mat, 1)`라고 코딩하면 되고, 각 열마다 softmax를 적용하고 싶으면 `torch.softmax(mat, 0)` 이라고 코딩하면 됩니다. 마지막 인덱스를 `-1`로 쓸 수 있으므로, `1`대신 `-1`이라고 해도 됩니다.\n",
        "\n",
        "**Challenge**\n",
        "- 3차원 이상의 텐서의 경우 어떤 식으로 해야할지, 잘 생각해보시고, 구현하여 본인 생각이 맞는지 확인해보세요.\n",
        "- https://medium.com/analytics-vidhya/an-intuitive-understanding-on-tensor-sum-dimension-with-pytorch-d9b0b6ebbae\n",
        "- https://jamesmccaffrey.wordpress.com/2020/07/09/understanding-the-dim-parameter-in-pytorch-functions/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6KqfbUqO_hU"
      },
      "source": [
        "### RNN 네트워크 구조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwRz6kw-4X4g"
      },
      "source": [
        "다음과 같이 `nn.Module`을 상속하여 PyTorch의 신경망을 클래스로 정의할 수 있습니다. 네트워크 구조가 어떻게 코드로 구현되는지 잘 살펴보세요.\n",
        "\n",
        "**Quiz**\n",
        "- `nn.Linear`는 몇 개의 parameter를 가지고 있을까요?\n",
        "- 입력 텐서의 shape가 (x, x, x) 일 때, `nn.Linear(x, y)`를 거치면 어떻게 될까요? (직접 해보세요)\n",
        "- `nn.LogSoftmax`는 몇 개의 parameter를 가지고 있을까요?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVuqoJtx4dNG"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim = 0)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
        "        output = self.h2o(hidden)\n",
        "\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(self.hidden_size)\n",
        "\n",
        "n_hidden = 32\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v46Zm1WHIF2D"
      },
      "source": [
        "**Challenge**\n",
        "- `nn.Linear`를 PyTorch를 사용하지 말고 구현해보세요.\n",
        "- `nn.LogSoftmax`를 PyTorch를 사용하지 말고 구현해보세요.\n",
        "- `nn.Softmax`를 PyTorch를 사용하지 말고 구현해보세요.\n",
        "- `torch.allclose`등을 사용해 정확히 구현되었는지 결과값을 비교하여 검증하세요. 필요하다면, 레이어 내부에 저장된 weight를 꺼내어 쓰세요.\n",
        "- 이 과정에서 PyTorch의 공식문서를 참조하시면 좋습니다.\n",
        "- (difficult) forward뿐만 아니라 backward도 구현해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Egf-3oyF4YS"
      },
      "source": [
        "RNN은 출력값을 입력값으로 재사용합니다.\n",
        "\n",
        "이 때, *재사용*이 어떻게 코드로 구현되는지 다음 코드를 읽고 이해하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk2VS86U-r9V",
        "outputId": "7e5610e7-d1c8-458d-b449-ab32da16921d"
      },
      "outputs": [],
      "source": [
        "# Example Inference using RNN\n",
        "\n",
        "input = lineToTensor('jake') # (4, 26)\n",
        "hidden0 = torch.zeros(n_hidden) # (1, n_hidden)\n",
        "\n",
        "with torch.no_grad(): # No training, no gradient\n",
        "    out1, hidden1 = rnn(input[0], hidden0) # 1st character 'j'\n",
        "    out2, hidden2 = rnn(input[1], hidden1) # 2nd character 'a'\n",
        "    out3, hidden3 = rnn(input[2], hidden2) # 3rd character 'k'\n",
        "    out4, hidden4 = rnn(input[3], hidden3) # 4th character 'e'\n",
        "out = out4\n",
        "\n",
        "print(out) # (n_categories)\n",
        "\n",
        "# The output is meaningless because the network is not yet trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXjzX_6FFAUf"
      },
      "source": [
        "위 셀의 출력 텐서 `out`을 어떻게 해석해야 할까요?\n",
        "\n",
        "일단 학습되지 않아서 의미없는 예시 값이지만, 분명 18개의 언어 카테고리 각각의 확률을 표시해주는 값이어야 핪니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj-f8BQfLDdj"
      },
      "source": [
        "log softmax는 그냥 softmax 이후에 log를 취한 값입니다.\n",
        "\n",
        "log softmax에서 softmax를 얻고 싶으면? log의 역연산인 exp를 취하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxmrFmsZJvt2",
        "outputId": "b3093745-842d-4139-f379-50839d75bca8"
      },
      "outputs": [],
      "source": [
        "print(torch.exp(out))\n",
        "print(torch.sum(torch.exp(out)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8LSiOFqReZ2"
      },
      "source": [
        "아직 학습이 되지 않아 그저 랜덤한 확률값이 출력됩니다. 학습의 목표는 적절한 확률값이 출력되도록 하는 것입니다.\n",
        "\n",
        "확률에 로그를 취하든 취하지 않든 가장 큰 값이 결국 네트워크의 예측값이 됩니다. 다음은 확률이 가장 높은 카테고리를 고르는 헬퍼 함수입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVpxYXXQUjd9",
        "outputId": "7c476e9d-f988-426c-c156-d79af2354f17"
      },
      "outputs": [],
      "source": [
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(categoryFromOutput(out))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7ETT5imDyjA"
      },
      "source": [
        "### 네트워크 학습\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKItwE3KSdnL"
      },
      "source": [
        "```\n",
        "면접관: 당신의 장점은?\n",
        "나: 저는 머신러닝 전문가입니다.\n",
        "면접관: 9+10은?\n",
        "나: 3 입니다.\n",
        "면접관: 틀렸네. 전혀 달라. 답은 19일세.\n",
        "나: 16 입니다.\n",
        "면접관: 틀렸네. 답은 19일세.\n",
        "나: 18 입니다.\n",
        "면접관: 틀렸네. 답은 19일세.\n",
        "나: 19 입니다.\n",
        "면접관: 자넨 합격일세.\n",
        "```\n",
        "\n",
        "위는 놀랍게도 실제 뉴럴네트워크의 학습 과정입니다. 다만 아래와 같이 좀 더 정확하게 고칠 수 있습니다.\n",
        "\n",
        "```\n",
        "훈련교관: 9+10은?\n",
        "신경망: 3입니다.\n",
        "훈련교관: 답은 19일세.\n",
        "신경망: 명심하겠습니다.\n",
        "\n",
        "훈련교관: 8+45는?\n",
        "신경망: 20입니다.\n",
        "훈련교관: 답은 53일세.\n",
        "신경망: 명심하겠습니다.\n",
        "\n",
        "훈련교관: 10+15는? (1. 학습 데이터 샘플링)\n",
        "신경망: 78입니다. (2. 추론)\n",
        "훈련교관: 답은 25일세. (3. 정답과 비교해서 손실함수 계산)\n",
        "신경망: 명심하겠습니다. (4. 손실함수에서 역전파된 그래디언트를 바탕으로 파라미터 조정)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54G-Ts_3XHiQ",
        "outputId": "68fa093d-36bb-4a7d-b4e9-02e843d7e5d6"
      },
      "outputs": [],
      "source": [
        "# Helper functions for training\n",
        "\n",
        "import random\n",
        "\n",
        "def randomTrainingExample():\n",
        "    category = random.sample(all_categories, 1)[0]\n",
        "    line = random.sample((category_names[category]), 1)[0]\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    line_tensor = lineToTensor(line)\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "# Show examples\n",
        "for i in range(10):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    print('category =', category, '/ line =', line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QPbz-PzZyQ1"
      },
      "source": [
        "학습 데이터 랜덤 샘플링 단계와 추론 단계만으로 구성된 불완전한 트레이닝 코드는 아래와 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct5wOTcwZxWj",
        "outputId": "630180d2-9a46-4970-ddf5-c6e31446bf4b"
      },
      "outputs": [],
      "source": [
        "def infer(rnn, line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "    return output\n",
        "\n",
        "for step in range(10):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output = infer(rnn, line_tensor)\n",
        "    print(line, category, categoryFromOutput(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRrTGn7rY7xZ"
      },
      "source": [
        "여기에서 손실 함수 계산 단계를 더하기 전에, 손실 함수 자체에 대해 좀 더 알아보겠습니다.\n",
        "\n",
        "본 실습에서는 손실함수로 `torch.nn.NLLLoss`를 사용합니다. 이 함수는 기본적으로 다음과 같이 작동합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6xJcP3ZZbfY",
        "outputId": "06b031d4-63cb-4708-e76b-f2b9658d2800"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.NLLLoss()\n",
        "aaa = torch.tensor([[11, 22, 33, 44, 55]], dtype=torch.float32)\n",
        "print(loss_fn(aaa, torch.tensor([0])))\n",
        "print(loss_fn(aaa, torch.tensor([1])))\n",
        "print(loss_fn(aaa, torch.tensor([2])))\n",
        "print(loss_fn(aaa, torch.tensor([3])))\n",
        "print(loss_fn(aaa, torch.tensor([4])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9z3xyGew0w"
      },
      "source": [
        "위 셀에서 `aaa`는 임의의 텐서입니다. `torch.nn.NLLLoss`는 텐서에서 특정 인덱스에 해당하는 값을 뽑아 -1을 곱한 후 돌려줍니다. 복잡한 수식 계산을 하지는 않습니다.\n",
        "\n",
        "**Challenge**\n",
        "- `torch.nn.NLLLoss`를 직접 구현하세요. 만약 forward와 backward를 모두 구현한다면 학습에도 사용할 수 있을 것입니다.\n",
        "\n",
        "저희가 구현한 RNN의 출력값은 log softmax라는 의미를 지닙니다. 만약 log softmax가 아니라 그냥 softmax였다면, 정답 카테고리의 출력값은 1, 나머지는 0이 되는 것이 이상적입니다. 그러나 log를 적용하면, 정답 카테코리의 출력값은 0, 나머지는 -inf가 되는 것이 이상적입니다. 이번 학습에서는 정답 카테고리의 출력값만 고려하겠습니다.\n",
        "\n",
        "예시를 들어보겠습니다. 만약 RNN의 출력값이 다음과 같고, 정답 카테고리의 인덱스는 0이라고 합시다.\n",
        "\n",
        "```\n",
        "tensor([[-2.9579, -2.7449, -2.9624, -2.7420, -2.8171, -3.0771, -2.7278, -3.0051,\n",
        "         -3.0478, -2.9685, -2.5545, -2.8554, -3.2244, -3.1169, -2.5231, -2.8236,\n",
        "         -3.1662, -3.0583]])\n",
        "```\n",
        "\n",
        "그렇다면 저희가 원하는 것은 0번째 인덱스이 값인 `-2.9579`가 0에 가까워지는 것입니다. 다른 말로 하면, -1을 곱한 값인 `2.9579`가 낮아지는 것입니다.\n",
        "\n",
        "위와 같은 점을 고려하여 `torch.nn.NLLLoss`를 사용하여 손실함수 계산까지 구현하면 다음과 같습니다.\n",
        "\n",
        "1. 학습 데이터 샘플링 (구현함)\n",
        "2. 추론 (구현함)\n",
        "3. 정답과 비교하여 손실함수 계산 (구현함)\n",
        "4. 파라미터 조정 (아직 구현안함)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI-_5r7riTx_",
        "outputId": "c31652d8-42a7-462b-8927-82e0537f3a28"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "for step in range(10):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output = infer(rnn, line_tensor)\n",
        "    output = torch.unsqueeze(output, dim = 0)\n",
        "    loss = criterion(output, category_tensor)\n",
        "    print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caxmmUesivS0"
      },
      "source": [
        "학습이 잘 된다면 이렇게 계산한 손실함수가 학습과정중에 점점 낮아져야 합니다.\n",
        "\n",
        "이제 모든 단계를 포함하여 학습 코드를 구현하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM_Gg_ahiuft",
        "outputId": "1b15466e-1524-4457-bef6-a9f2a15a7c7b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "optim = torch.optim.Adam(rnn.parameters(), 1e-3)\n",
        "\n",
        "for step in range(10000):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    output = infer(rnn, line_tensor)\n",
        "    output = torch.unsqueeze(output, dim = 0)\n",
        "    loss = criterion(output, category_tensor)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    if step % 1000 == 0:\n",
        "        print(step, loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aWUBLtAl1JJ"
      },
      "source": [
        "**Challenge**\n",
        "- 배치 크기를 키운 학습을 구현하세요.\n",
        "- 데이터를 학습 데이터와 테스트 데이터로 구분하고 epoch을 나눠 구현하세요.\n",
        "- learning rate, hidden layer size 등을 조절하며 더 최적화해 보세요.\n",
        "- vanishing/exploding gradient 현상이 일어나고 있는 것은 아닌지 조사하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er8P2Jh0kVTs"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvSbmwB6kb8Y",
        "outputId": "6884e962-7366-42a2-e299-817ece02b143"
      },
      "outputs": [],
      "source": [
        "cnt = 0\n",
        "cnt_correct = 0\n",
        "\n",
        "for step in range(1000):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    with torch.no_grad():\n",
        "        output = infer(rnn, line_tensor)\n",
        "    cnt += 1\n",
        "    cnt_correct += 1 if category == categoryFromOutput(output)[0] else 0\n",
        "\n",
        "print(f'Accuracy {cnt_correct}/{cnt}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xN5jjYflr1oE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
