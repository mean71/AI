{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(torch.tensor)\n",
    "# dir(torch.tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - is_tensor\n",
    " - is_storage\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1, 2], [3, 4]], dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "# device='cuda'\n",
    "# requires_grad=True\n",
    "# 사람이 키고 끄라고 있는게 아니라 모델 설계할때 모드변경하면서 알아서 키고 끄도록 달린 인수인듯하다\n",
    "\n",
    "# PyTorch 텐서의 데이터 타입 (dtype) 목록\n",
    "\n",
    "# 1. 정수형 (Integer types)\n",
    "# torch.int8    : 8비트 부호 있는 정수 (-128 ~ 127)\n",
    "# torch.uint8   : 8비트 부호 없는 정수 (0 ~ 255)\n",
    "# torch.int16   : 16비트 부호 있는 정수 (-32,768 ~ 32,767)\n",
    "# torch.short   : torch.int16의 별칭\n",
    "# torch.int32   : 32비트 부호 있는 정수 (-2,147,483,648 ~ 2,147,483,647)\n",
    "# torch.int     : torch.int32의 별칭\n",
    "# torch.int64   : 64비트 부호 있는 정수 (-9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,807)\n",
    "# torch.long    : torch.int64의 별칭\n",
    "\n",
    "# 2. 실수형 (Floating point types)\n",
    "# torch.float16 : 16비트 부동소수점\n",
    "# torch.half    : torch.float16의 별칭\n",
    "# torch.float32 : 32비트 부동소수점 (기본 값)\n",
    "# torch.float   : torch.float32의 별칭\n",
    "# torch.float64 : 64비트 부동소수점\n",
    "# torch.double  : torch.float64의 별칭\n",
    "\n",
    "# 3. 복소수형 (Complex types)\n",
    "# torch.complex64  : 64비트 복소수 (실수 32비트 + 허수 32비트)\n",
    "# torch.complex128 : 128비트 복소수 (실수 64비트 + 허수 64비트)\n",
    "\n",
    "# 4. 불리언 타입 (Boolean type)\n",
    "# torch.bool   : 참(True) 또는 거짓(False) 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch의 데이터를 처리하는 두 가지 기본형\\\n",
    "torch.utils.data.DataLoader\\\n",
    "torch.utils.data.Dataset\\\n",
    "Dataset샘플과 해당 레이블을 저장하고.DataLoader가 Dataset을 반복 가능한 객체로 래핑."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets\n",
    "# from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "'''torch.nn.BCEWithLogitsLoss()\n",
    "Binary Cross-Entropy with Logits Loss 함수\n",
    "이진 분류문제에서 자주 사용됩니다.\n",
    "이진 크로스 엔트로피 손실(Binary Cross-Entropy Loss, BCE Loss)과 로짓(logits)을 결합한 방식\n",
    "모델의 출력값이 시그모이드 함수를 통과한 것처럼 다루어집니다.'''\n",
    "# 비가 오면 1, 안 오면 0\n",
    "a = criterion(torch.tensor([10.]), torch.tensor([1.]))\n",
    "b = criterion(torch.tensor([10.]), torch.tensor([0.]))\n",
    "c = criterion(torch.tensor([-6.]), torch.tensor([1.]))\n",
    "d = criterion(torch.tensor([-6.]), torch.tensor([0.]))\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "assert a < b\n",
    "assert a < c\n",
    "assert d < b\n",
    "assert d < c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN (Recurrent Neural Network, 순환 신경망)\n",
    "\n",
    "RNN은 **시퀀스 데이터**를 처리할 수 있는 신경망 구조입니다. 기존의 인공 신경망(ANN)과 달리, RNN은 **순차적 데이터의 시간적인 의존성**을 학습할 수 있습니다. 이는 자연어 처리(NLP), 시계열 데이터 분석, 음악 생성 등 연속적인 데이터를 다룰 때 매우 유용합니다.\n",
    "\n",
    "### RNN의 특징\n",
    "1. **순환 구조**: RNN은 각 타임스텝에서 **이전 상태(hidden state)**를 다음 타임스텝으로 전달합니다. 이로 인해 과거 정보가 현재 출력에 영향을 미칠 수 있습니다.\n",
    "2. **시퀀스 학습**: 입력 데이터가 시간 순서에 따라 주어지며, 순차적으로 처리됩니다.\n",
    "3. **기억 능력**: RNN은 이전 타임스텝의 정보를 기억하여 이후 타임스텝에서 사용합니다. 하지만, **장기 의존성**을 다루는 데 한계가 있어, 이를 해결하기 위해 LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit)와 같은 변형이 자주 사용됩니다.\n",
    "\n",
    "### RNN의 수식\n",
    "RNN의 각 타임스텝에서의 계산은 다음과 같이 이루어집니다:\n",
    "\n",
    "\\[\n",
    "h_t = \\tanh(W_{hh} h_{t-1} + W_{xh} x_t)\n",
    "\\]\n",
    "\\[\n",
    "y_t = W_{hy} h_t\n",
    "\\]\n",
    "\n",
    "- **\\( h_t \\)**: 현재 타임스텝에서의 **히든 상태** (hidden state)\n",
    "- **\\( x_t \\)**: 현재 타임스텝에서의 입력값\n",
    "- **\\( y_t \\)**: 현재 타임스텝에서의 **출력값**\n",
    "- **\\( W_{hh}, W_{xh}, W_{hy} \\)**: 가중치 행렬\n",
    "\n",
    "---\n",
    "\n",
    "## RNN의 히든 상태와 출력의 차이\n",
    "\n",
    "### 1. **히든 상태 (Hidden State)**\n",
    "- **정의**: 히든 상태는 RNN이 시퀀스의 **이전 정보**를 저장하는 공간입니다. 이는 RNN이 과거 입력의 정보(기억)를 저장하고, 이를 현재의 입력과 함께 처리하여 **현재 상태**를 계산하는 데 사용됩니다.\n",
    "- **역할**: 시퀀스의 **이전 정보**를 유지하고 전달하는 역할을 합니다. 각 타임스텝마다 갱신되며, 다음 타임스텝의 계산에 반영됩니다.\n",
    "- **출력**: 히든 상태는 최종 예측값을 만드는 데 중요한 중간 상태이지만, 최종 출력값 그 자체는 아닙니다.\n",
    "\n",
    "### 2. **출력 (Output)**\n",
    "- **정의**: 출력은 RNN이 각 타임스텝에서 계산한 **결과 값**입니다. 이는 히든 상태를 기반으로 계산되며, 모델의 예측값으로 사용됩니다.\n",
    "- **역할**: 각 타임스텝에서 RNN이 예측한 값으로, 실제로 우리가 원하는 출력입니다.\n",
    "- **출력과 히든 상태의 관계**: 출력은 히든 상태로부터 계산되며, 히든 상태는 RNN의 내부적인 '기억' 역할을 수행하는 반면, 출력은 네트워크가 최종적으로 내놓는 예측값입니다.\n",
    "\n",
    "---\n",
    "\n",
    "### RNN 구조\n",
    "\n",
    "```plaintext\n",
    "x₁ → (h₁) → y₁\n",
    "      ↑\n",
    "x₂ → (h₂) → y₂\n",
    "      ↑\n",
    "x₃ → (h₃) → y₃\n",
    "```\n",
    "\n",
    "- \\( x_t \\): t 번째 타임스텝에서 입력값\n",
    "- \\( h_t \\): t 번째 타임스텝에서 히든 상태\n",
    "- \\( y_t \\): t 번째 타임스텝에서 출력값\n",
    "\n",
    "---\n",
    "\n",
    "### 출력 설명\n",
    "- **`output`**: 시퀀스의 각 타임스텝에서 RNN이 출력한 값. 크기는 `(배치 크기, 시퀀스 길이, 히든 상태 크기)`로 나타납니다.\n",
    "- **`hidden`**: 최종 타임스텝의 히든 상태. 이는 **모든 레이어**의 마지막 히든 상태를 담고 있으며, 크기는 `(레이어 수, 배치 크기, 히든 상태 크기)`입니다.\n",
    "\n",
    "### 선택 기준 요약:\n",
    "- **히든 상태**: RNN의 내부 상태로, 과거 정보를 저장하며 타임스텝마다 업데이트됩니다.\n",
    "- **출력**: RNN의 예측 결과로, 각 타임스텝에서 히든 상태를 기반으로 계산된 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PyTorch를 이용한 RNN 예시\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# RNN 모델 생성 (입력 크기: 10, 히든 상태 크기: 20, 레이어 수: 2)\n",
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "# 입력 데이터: (배치 크기, 시퀀스 길이, 입력 크기)\n",
    "inputs = torch.randn(5, 3, 10)  # 배치 크기 5, 시퀀스 길이 3, 입력 크기 10\n",
    "# 초기 히든 상태: (레이어 수, 배치 크기, 히든 크기)\n",
    "h0 = torch.zeros(2, 5, 20)\n",
    "# RNN 실행\n",
    "output, hidden = rnn(inputs, h0)\n",
    "# output: (배치 크기, 시퀀스 길이, 히든 상태 크기) = (5, 3, 20)\n",
    "# hidden: (레이어 수, 배치 크기, 히든 상태 크기) = (2, 5, 20)\n",
    "print(\"RNN Output Shape:\", output.shape)\n",
    "print(\"RNN Hidden Shape:\", hidden.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
