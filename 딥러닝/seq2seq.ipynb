{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], loss: 1.5230573676526546\n",
            "Epoch [2/20], loss: 1.411104254424572\n",
            "Epoch [3/20], loss: 1.3869245052337646\n",
            "Epoch [4/20], loss: 1.3727898225188255\n",
            "Epoch [5/20], loss: 1.3576303720474243\n",
            "Epoch [6/20], loss: 1.344936266541481\n",
            "Epoch [7/20], loss: 1.3282239697873592\n",
            "Epoch [8/20], loss: 1.311855487525463\n",
            "Epoch [9/20], loss: 1.2975837476551533\n",
            "Epoch [10/20], loss: 1.282768189907074\n",
            "Epoch [11/20], loss: 1.2677641957998276\n",
            "Epoch [12/20], loss: 1.2532121017575264\n",
            "Epoch [13/20], loss: 1.2403131611645222\n",
            "Epoch [14/20], loss: 1.229046680033207\n",
            "Epoch [15/20], loss: 1.2158268615603447\n",
            "Epoch [16/20], loss: 1.2040522210299969\n",
            "Epoch [17/20], loss: 1.1925436593592167\n",
            "Epoch [18/20], loss: 1.1816879659891129\n",
            "Epoch [19/20], loss: 1.171809360384941\n",
            "Epoch [20/20], loss: 1.1587859317660332\n",
            "Training Accuracy: 53.62%\n",
            "\n",
            "Sample Input Sequence:    [2, 2, 2, 3, 2, 4, 4, 1, 3, 4]\n",
            "Sample Target Sequence:   [2, 2, 2, 3, 2, 4, 4, 1, 3, 4]\n",
            "Predicted Sequence       :   [2, 2, 4, 4, 4, 4, 4, 4, 4, 4]\n",
            "tensor([2, 2, 2, 3, 2, 4, 4, 1, 3, 4]) tensor([2, 2, 2, 3, 2, 4, 4, 1, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def generate_dataset(seq_length, num_samples, vocab_size): # vocab_size:\n",
        "    inputs = torch.randint(1, vocab_size, (num_samples, seq_length))\n",
        "    outputs = inputs.clone()\n",
        "    return TensorDataset(inputs, outputs)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear = nn.Linear(input_size, hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "    \n",
        "    def forward(self, input_seq):\n",
        "        batch_size, seq_length = input_seq.size() # batch_size, seq_length\n",
        "        hidden = torch.zeros(batch_size, self.hidden_size)\n",
        "        \n",
        "        for char_idx in range(seq_length):\n",
        "            x_t = nn.functional.one_hot(input_seq[:, char_idx], num_classes = self.linear.in_features).float()\n",
        "            hidden = self.activation(self.linear(x_t) + hidden)\n",
        "        return hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # self.i2h = nn.Linear(input_size, hidden_size) # input -> hidden\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, target_seq, hidden):\n",
        "        batch_size, seq_len = target_seq.size()\n",
        "        outputs = torch.zeros(batch_size, seq_len, self.output_size)\n",
        "        \n",
        "        for char_idx in range(seq_len):\n",
        "            if char_idx == 0:\n",
        "                previous_y = torch.zeros(batch_size, self.input_size)\n",
        "            else:\n",
        "                y_prev = target_seq[:, char_idx -1]\n",
        "                previous_y = nn.functional.one_hot(y_prev, self.input_size).float()\n",
        "            hidden = self.activation(self.linear1(previous_y) + hidden)\n",
        "            output = self.linear2(hidden)\n",
        "            outputs[:, char_idx, :] = output\n",
        "        return outputs\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, target_seq):\n",
        "        encoder_hidden = self.encoder(input_seq)\n",
        "        decoder_output = self.decoder(target_seq, encoder_hidden)\n",
        "        return decoder_output\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs, device):\n",
        "    model.to(device)\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for inputs, targets in dataloader:\n",
        "            # inputs.shape - batch_size, sequence_length\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = model(inputs, targets)\n",
        "            outputs = outputs.view(-1, outputs.size(-1)) # batch_size * seq_size, output_size\n",
        "            targets = targets.view(-1) # batch_size * seq_len\n",
        "            loss = criterion(outputs, targets)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], loss: {avg_loss}')\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs, targets) # batch_size, seq_length, vocab_size\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim = 2)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.size(0) * targets.size(1)\n",
        "    acc = correct / total\n",
        "    return acc\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    seq_length = 10\n",
        "    num_samples = 1000\n",
        "    vocab_size = 5  # Including a padding index if needed\n",
        "    hidden_size = 64\n",
        "    batch_size = 32\n",
        "    num_epochs = 20\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # print(f\"Using device: {device}\")\n",
        "\n",
        "    dataset = generate_dataset(seq_length, num_samples, vocab_size)\n",
        "    dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "    encoder = Encoder(input_size = vocab_size, hidden_size = hidden_size)\n",
        "    decoder = Decoder(input_size = vocab_size, hidden_size = hidden_size, output_size = vocab_size)\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "    train_model(model, dataloader, criterion, optimizer, num_epochs, device)\n",
        "\n",
        "    acc = evaluate_model(model, dataloader, device)\n",
        "    print(f\"Training Accuracy: {acc * 100:.2f}%\\n\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        test_input, test_target = dataset[0]\n",
        "        test_input = test_input.unsqueeze(0).to(device)\n",
        "        test_target = test_target.unsqueeze(0).to(device)\n",
        "\n",
        "        output = model(test_input, test_target)\n",
        "\n",
        "        predicted = torch.argmax(output, dim = 2)\n",
        "        print(\"Sample Input Sequence:   \", test_input.squeeze().tolist())\n",
        "        print(\"Sample Target Sequence:  \", test_target.squeeze().tolist())\n",
        "        print(\"Predicted Sequence       :  \", predicted.squeeze().tolist())\n",
        "    \n",
        "    for x, y in dataset:\n",
        "        print(x, y)\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RNN의 파라미터 수를 계산하는 방법에 대해 설명해 드리겠습니다. 입력층과 은닉층 사이의 파라미터를 중심으로 설명하겠습니다.\n",
        "RNN 파라미터 구조\n",
        "RNN의 기본 구조에서 입력층과 은닉층 사이의 파라미터는 다음과 같습니다:\n",
        "입력 가중치 (Wx)\n",
        "은닉 상태 가중치 (Wh)\n",
        "편향 (b)\n",
        "파라미터 수 계산\n",
        "입력 가중치 (Wx)\n",
        "크기: $D_h \\times d$\n",
        "$D_h$: 은닉 상태의 크기\n",
        "$d$: 입력 벡터의 차원\n",
        "파라미터 수: $D_h \\times d$\n",
        "은닉 상태 가중치 (Wh)\n",
        "크기: $D_h \\times D_h$\n",
        "파라미터 수: $D_h \\times D_h$\n",
        "편향 (b)\n",
        "크기: $D_h \\times 1$\n",
        "파라미터 수: $D_h$\n",
        "총 파라미터 수\n",
        "총 파라미터 수는 위의 세 가지 파라미터를 합한 것입니다:\n",
        "(\n",
        "D\n",
        "h\n",
        "×\n",
        "d\n",
        ")\n",
        "+\n",
        "(\n",
        "D\n",
        "h\n",
        "×\n",
        "D\n",
        "h\n",
        ")\n",
        "+\n",
        "D\n",
        "h\n",
        "(D \n",
        "h\n",
        "​\n",
        " ×d)+(D \n",
        "h\n",
        "​\n",
        " ×D \n",
        "h\n",
        "​\n",
        " )+D \n",
        "h\n",
        "​\n",
        " \n",
        "예시 계산\n",
        "입력 벡터의 차원($d$)이 4이고, 은닉 상태의 크기($D_h$)가 5인 경우:\n",
        "Wx: $5 \\times 4 = 20$\n",
        "Wh: $5 \\times 5 = 25$\n",
        "b: $5$\n",
        "총 파라미터 수: $20 + 25 + 5 = 50$\n",
        "이렇게 RNN의 입력층과 은닉층 사이의 파라미터 수를 계산할 수 있습니다. 이 구조는 시간에 따라 같은 가중치를 공유하므로, 시간 단계가 늘어나도 파라미터 수는 변하지 않습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2, 3, 1, 1, 1],\n",
            "        [3, 3, 1, 2, 3],\n",
            "        [1, 1, 2, 3, 2],\n",
            "        [1, 2, 3, 3, 2]])\n",
            "torch.Size([4, 5])\n",
            "tensor([1, 2, 3, 3])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Class values must be smaller than num_classes.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_seq\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_seq[:, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(one_hot\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(one_hot)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Class values must be smaller than num_classes."
          ]
        }
      ],
      "source": [
        "input_sequence = [torch.randint(1, 4, (5,)) for _ in range(4)]\n",
        "input_seq = torch.stack(input_sequence)\n",
        "\n",
        "print(input_seq)\n",
        "print(input_seq.shape)\n",
        "print(input_seq[:, 3])\n",
        "one_hot = nn.functional.one_hot(input_seq[:, 3], 3)\n",
        "print(one_hot.shape)\n",
        "print(one_hot)\n",
        "# 1 2 3\n",
        "# [1, 0, 0]\n",
        "# [0, 1, 0]\n",
        "# [0, 0, 1]\n",
        "# X_t = nn.functional.one_hot(input_seq[:, char_idx],\n",
        "                            # num_calsses = self.linear.in_features).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb2dAASy8QPf",
        "outputId": "ae022fdd-3843-4e14-f811-a3fca52bb5fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Starting training...\n",
            "Epoch [1/20], Loss: 3.9003\n",
            "Epoch [2/20], Loss: 3.8393\n",
            "Epoch [3/20], Loss: 3.7734\n",
            "Epoch [4/20], Loss: 3.6947\n",
            "Epoch [5/20], Loss: 3.6141\n",
            "Epoch [6/20], Loss: 3.5328\n",
            "Epoch [7/20], Loss: 3.4544\n",
            "Epoch [8/20], Loss: 3.3807\n",
            "Epoch [9/20], Loss: 3.3112\n",
            "Epoch [10/20], Loss: 3.2445\n",
            "Epoch [11/20], Loss: 3.1801\n",
            "Epoch [12/20], Loss: 3.1218\n",
            "Epoch [13/20], Loss: 3.0658\n",
            "Epoch [14/20], Loss: 3.0160\n",
            "Epoch [15/20], Loss: 2.9699\n",
            "Epoch [16/20], Loss: 2.9272\n",
            "Epoch [17/20], Loss: 2.8868\n",
            "Epoch [18/20], Loss: 2.8503\n",
            "Epoch [19/20], Loss: 2.8156\n",
            "Epoch [20/20], Loss: 2.7828\n",
            "Training completed.\n",
            "\n",
            "Training Accuracy: 26.06%\n",
            "\n",
            "Sample Input Sequence:    [6, 3, 11, 14, 22, 46, 35, 43, 42, 18]\n",
            "Sample Target Sequence:   [6, 3, 11, 14, 22, 46, 35, 43, 42, 18]\n",
            "Predicted Sequence       :   [42, 35, 35, 42, 42, 18, 42, 42, 42, 18]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def generate_dataset(seq_length, num_samples, vocab_size):\n",
        "    \"\"\"\n",
        "    Generates a synthetic dataset where each input sequence is identical to the output sequence.\n",
        "\n",
        "    Args:\n",
        "        seq_length (int): The length of each sequence.\n",
        "        num_samples (int): The number of samples in the dataset.\n",
        "        vocab_size (int): The size of the vocabulary (number of unique tokens).\n",
        "\n",
        "    Returns:\n",
        "        TensorDataset: A dataset containing input and output sequences.\n",
        "    \"\"\"\n",
        "    # Generate random integers between 1 and vocab_size-1 for input sequences\n",
        "    inputs = torch.randint(1, vocab_size, (num_samples, seq_length))\n",
        "    outputs = inputs.clone()  # Output is the same as input\n",
        "    return TensorDataset(inputs, outputs)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    RNN Encoder implemented with nn.Linear layers.\n",
        "\n",
        "    Architecture:\n",
        "        Input -> Linear -> Tanh -> Hidden State\n",
        "        Repeats for each time step.\n",
        "\n",
        "        x_t ----> [Linear] ----> [Tanh] ----> h_t\n",
        "\n",
        "    Model Formula:\n",
        "        h_t = tanh(W_x * x_t + W_h * h_{t-1} + b)\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features (vocab size).\n",
        "        hidden_size (int): Size of hidden state.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear = nn.Linear(input_size, hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        \"\"\"\n",
        "        Forward pass for the encoder.\n",
        "\n",
        "        Args:\n",
        "            input_seq (Tensor): Input sequence tensor of shape (batch, seq_len).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Final hidden state tensor of shape (batch, hidden_size).\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = input_seq.size()\n",
        "        # Initialize hidden state to zeros\n",
        "        hidden = torch.zeros(batch_size, self.hidden_size)\n",
        "        for t in range(seq_len):\n",
        "            # One-hot encode input tokens\n",
        "            x_t = nn.functional.one_hot(input_seq[:, t], num_classes=self.linear.in_features).float()\n",
        "            hidden = self.activation(self.linear(x_t) + hidden)\n",
        "        return hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    RNN Decoder implemented with nn.Linear layers.\n",
        "\n",
        "    Architecture:\n",
        "        Input -> Linear -> Tanh -> Hidden State -> Linear -> Output\n",
        "        Repeats for each time step.\n",
        "\n",
        "        y_{t-1} ----> [Linear] ----> [Tanh] ----> h_t ----> [Linear] ----> y_t\n",
        "\n",
        "    Model Formula:\n",
        "        h_t = tanh(W_x * y_{t-1} + W_h * h_{t-1} + b)\n",
        "        y_t = W_o * h_t + b_o\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of input features (vocab size).\n",
        "        hidden_size (int): Size of hidden state.\n",
        "        output_size (int): Size of output features (vocab size).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, target_seq, hidden):\n",
        "        \"\"\"\n",
        "        Forward pass for the decoder.\n",
        "\n",
        "        Args:\n",
        "            target_seq (Tensor): Target sequence tensor of shape (batch, seq_len).\n",
        "            hidden (Tensor): Hidden state tensor of shape (batch, hidden_size).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Output logits of shape (batch, seq_len, output_size).\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = target_seq.size()\n",
        "        outputs = torch.zeros(batch_size, seq_len, self.linear2.out_features)\n",
        "        for t in range(seq_len):\n",
        "            # During training, use teacher forcing: input is the actual target token\n",
        "            if t == 0:\n",
        "                # At t=0, use a start-of-sequence token (assuming index 0)\n",
        "                y_t_minus_1 = torch.zeros(batch_size, self.linear1.in_features, device=target_seq.device)\n",
        "            else:\n",
        "                y_prev = target_seq[:, t-1]\n",
        "                y_t_minus_1 = nn.functional.one_hot(y_prev, num_classes=self.linear1.in_features).float()\n",
        "            hidden = self.activation(self.linear1(y_t_minus_1) + hidden)\n",
        "            output = self.linear2(hidden)\n",
        "            outputs[:, t, :] = output\n",
        "        return outputs\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    \"\"\"\n",
        "    Sequence-to-Sequence model integrating Encoder and Decoder.\n",
        "\n",
        "    Architecture:\n",
        "        Encoder -> Decoder\n",
        "\n",
        "    Args:\n",
        "        encoder (nn.Module): Encoder module.\n",
        "        decoder (nn.Module): Decoder module.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, target_seq):\n",
        "        \"\"\"\n",
        "        Forward pass for the Seq2Seq model.\n",
        "\n",
        "        Args:\n",
        "            input_seq (Tensor): Input sequence tensor of shape (batch, seq_len).\n",
        "            target_seq (Tensor): Target sequence tensor of shape (batch, seq_len).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Output logits of shape (batch, seq_len, output_size).\n",
        "        \"\"\"\n",
        "        encoder_hidden = self.encoder(input_seq)\n",
        "        decoder_output = self.decoder(target_seq, encoder_hidden)\n",
        "        return decoder_output\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs, device):\n",
        "    \"\"\"\n",
        "    Trains the Seq2Seq model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The Seq2Seq model to train.\n",
        "        dataloader (DataLoader): DataLoader for training data.\n",
        "        criterion (nn.Module): Loss function.\n",
        "        optimizer (optim.Optimizer): Optimizer for updating model parameters.\n",
        "        num_epochs (int): Number of training epochs.\n",
        "        device (torch.device): Device to run the training on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            outputs = model(inputs, targets)\n",
        "            # Reshape outputs and targets for loss computation\n",
        "            outputs = outputs.view(-1, outputs.size(-1))  # (batch * seq_len, output_size)\n",
        "            targets = targets.view(-1)  # (batch * seq_len)\n",
        "            loss = criterion(outputs, targets)\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        print(f\"Epoch [{epoch}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def evaluate_accuracy(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Evaluates the accuracy of the Seq2Seq model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The Seq2Seq model to evaluate.\n",
        "        dataloader (DataLoader): DataLoader for evaluation data.\n",
        "        device (torch.device): Device to run the evaluation on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of the model on the evaluation data.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs, targets)\n",
        "            # Get predicted tokens\n",
        "            predicted = torch.argmax(outputs, dim=2)\n",
        "            # Compare with targets\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.numel()\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Example usage and Training Code\n",
        "if __name__ == \"__main__\":\n",
        "    # Hyperparameters\n",
        "    seq_length = 10\n",
        "    num_samples = 1000\n",
        "    vocab_size = 50  # Including a padding index if needed\n",
        "    hidden_size = 64\n",
        "    batch_size = 32\n",
        "    num_epochs = 20\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Generate dataset\n",
        "    dataset = generate_dataset(seq_length, num_samples, vocab_size)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize Encoder and Decoder\n",
        "    encoder = Encoder(input_size=vocab_size, hidden_size=hidden_size)\n",
        "    decoder = Decoder(input_size=vocab_size, hidden_size=hidden_size, output_size=vocab_size)\n",
        "    model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Starting training...\")\n",
        "    train_model(model, dataloader, criterion, optimizer, num_epochs, device)\n",
        "    print(\"Training completed.\\n\")\n",
        "\n",
        "    # Evaluate accuracy on the training set\n",
        "    accuracy = evaluate_accuracy(model, dataloader, device)\n",
        "    print(f\"Training Accuracy: {accuracy * 100:.2f}%\\n\")\n",
        "\n",
        "    # Sample Output after Training\n",
        "    # Let's test the model on a sample input\n",
        "    with torch.no_grad():\n",
        "        test_input, test_target = dataset[0]\n",
        "        test_input = test_input.unsqueeze(0).to(device)  # (1, seq_len)\n",
        "        test_target = test_target.unsqueeze(0).to(device)  # (1, seq_len)\n",
        "        output = model(test_input, test_target)\n",
        "        predicted = torch.argmax(output, dim=2)\n",
        "        print(\"Sample Input Sequence:   \", test_input.squeeze().tolist())\n",
        "        print(\"Sample Target Sequence:  \", test_target.squeeze().tolist())\n",
        "        print(\"Predicted Sequence       :  \", predicted.squeeze().tolist())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
